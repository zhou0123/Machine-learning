{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据加载，划分测试集，训练集，预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Get_train_test(object):\n",
    "    def __init__(self,path):\n",
    "        self.path=path\n",
    "        \n",
    "    def Norm(self,data):\n",
    "        '''\n",
    "        标准化\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        data_max=data.max(axis=0)\n",
    "        data_min=data.min(axis=0)\n",
    "        \n",
    "        final_data=(data-data_min)/(data_max-data_min)\n",
    "        \n",
    "        return final_data\n",
    "    \n",
    "   \n",
    "    def get_random_number(self):\n",
    "        list_ram_num=[]\n",
    "        \n",
    "        while len(list_ram_num)<50:\n",
    "            \n",
    "            num=random.randint(0,207)\n",
    "            \n",
    "            list_ram_num.append(num)\n",
    "            \n",
    "            list_ram_num=list(set(list_ram_num))\n",
    "        return np.array(list_ram_num)\n",
    "        \n",
    "    def get_Data(self):\n",
    "        Data=pd.read_csv(self.path,header=None)\n",
    "        data=np.array(Data)[:,:-1]\n",
    "        labels=np.array(Data)[:,-1]\n",
    "        data=self.Norm(data)\n",
    "        random_num=self.get_random_number()\n",
    "        \n",
    "        test_ran=list(range(50))\n",
    "        np.random.shuffle(test_ran)\n",
    "        train_ran=list(range(158))\n",
    "        np.random.shuffle(train_ran)\n",
    "        data_test=data[random_num][test_ran]\n",
    "        label_test=labels[random_num][test_ran]\n",
    "      \n",
    "        data_train=np.delete(data,random_num,axis=0)[train_ran]\n",
    "        label_train=np.delete(labels,random_num,axis=0)[train_ran]\n",
    "        \n",
    "        return data_train,label_train,data_test,label_test\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train,label_train,data_test,label_test=Get_train_test('./相关资料/sonar.csv').get_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=np.concatenate((data_train,label_train.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树算法，后剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "class DecisionTree(object):\n",
    "    def __init__(self,algor=None,detla=0.01,root='0'):\n",
    "        self.algor=algor\n",
    "        self.detla=detla\n",
    "        self.root=root\n",
    "    #计算熵值\n",
    "    def cal_entropy(self,labels):\n",
    "        entropy=0.0\n",
    "        dic_1={}#计算每种标签出现的此数\n",
    "        for item in labels:\n",
    "            dic_1[item]=dic_1.get(item,0)+1\n",
    "        for itemN in dic_1:#计算每个标签占的比率\n",
    "            prod=dic_1[itemN]/len(labels)#概率\n",
    "            entropy-=prod*log(prod,2)#熵值\n",
    "        return entropy\n",
    "    #计算给定特征的各种划分下的最小熵值\n",
    "    def feaX_entropy(self,dataset,i):\n",
    "        entropy=0.0\n",
    "        feaX_labels=[[x[i],x[-1]] for x in dataset]#将待选择的特征与标签选出\n",
    "        feaX=[x[i] for x in dataset]\n",
    "        def takefirst(elem):\n",
    "            return elem[0]\n",
    "        feaX_labels.sort(key=takefirst)\n",
    "        feaX.sort()\n",
    "        candidate=[]#分割值的候选处\n",
    "        labels=[]\n",
    "        labels1=[]\n",
    "        entropy_list=[]\n",
    "        for i in range(len(feaX)-1):\n",
    "            candidate.append((feaX[i]+feaX[i+1])/2)\n",
    "        for candidate_sample in candidate:#计算每个分割值对应下的熵\n",
    "            count=0\n",
    "            for feaX_labels_sample in feaX_labels:\n",
    "                if candidate_sample<=feaX_labels_sample[0] :\n",
    "                    count+=1\n",
    "                    labels.append(feaX_labels_sample[-1])\n",
    "                else:\n",
    "                    labels1.append(feaX_labels_sample[-1])\n",
    "            entropy=count/len(feaX)*self.cal_entropy(labels)+(len(feaX)-count)/len(feaX)*self.cal_entropy(labels1)\n",
    "            entropy_list.append(entropy)#收成列表\n",
    "            #返回最小熵值，索引，和分割值\n",
    "        return min(entropy_list),entropy_list.index(min(entropy_list)),candidate[entropy_list.index(min(entropy_list))]\n",
    "      \n",
    "class ID3(DecisionTree):\n",
    "    def __init__(self,algor='ID3',detla=0.05):\n",
    "        super(ID3,self).__init__()\n",
    "        self.algor=algor\n",
    "        self.detla=detla\n",
    "    def info_gain(self,dataset,i):#计算信息增益\n",
    "        labels=[x[-1] for x in dataset]\n",
    "        entropy,index,candidate_final=self.feaX_entropy(dataset,i)\n",
    "        info_gain=self.cal_entropy(labels)-entropy\n",
    "        return info_gain\n",
    "    def find_max_info_gain(self,dataset):#遍历所有特征下的信息增益，返回最大的信息增益\n",
    "        num_sample=len(dataset[0])-1\n",
    "        find_max=[]\n",
    "        for i in range(num_sample):\n",
    "            find_max.append(self.info_gain(dataset,i))\n",
    "        return find_max.index(max(find_max)),max(find_max)\n",
    "    #构建决策树函数 返回列表\n",
    "    def creatdisiontree(self,dataset,fea_labels,detle):\n",
    "        labels=[x[-1]for x in dataset]#判断标签是否一致，若一致直接返回标签值\n",
    "        if len(list(set(labels)))==1:\n",
    "            return labels[0]\n",
    "        max_entropy_index,max_info_gain=self.find_max_info_gain(dataset)\n",
    "        if max_info_gain<detle:#判断最大信息增益是否小于给定值，若小于则不再生成树\n",
    "            label_count=Counter(labels)\n",
    "            return max(label_count.items(),key=lambda x:x[1])[0]\n",
    "        else:\n",
    "            fea_dic_val={}#用于收集分支的标志和下面的节点\n",
    "            fea_dic={}#用于收集节点和分支\n",
    "            feaX_labels=[[x[max_entropy_index],x[-1]]for x in dataset]\n",
    "            feaX=[x[max_entropy_index] for x in dataset]\n",
    "            fea_labels_new=[]#产生新的特征列表\n",
    "            fea_labels_new.extend(fea_labels[:max_entropy_index]+fea_labels[max_entropy_index+1:])\n",
    "            entropy,index,candidate_final=self.feaX_entropy(dataset,max_entropy_index)\n",
    "            tem_dict={'min_than %s'% (candidate_final):[],'max_than %s'%(candidate_final):[]}\n",
    "            for sample in feaX:#利用最终选取的划分值对样本进行划分\n",
    "                if sample<=candidate_final:\n",
    "                    tem_dict['min_than %s'% (candidate_final)].append(sample)\n",
    "                if sample>candidate_final:\n",
    "                    tem_dict['max_than %s'%(candidate_final)].append(sample)\n",
    "            data_new1=[]\n",
    "            data_new2=[]\n",
    "            for item in dataset:#对样本进行划分，并除去此特征生成新的特征列表\n",
    "                \n",
    "                if item[max_entropy_index] in tem_dict['min_than %s'% (candidate_final)]:\n",
    "                  \n",
    "                    data_new1.append(list(item[:max_entropy_index])+list(item[max_entropy_index+1:]))\n",
    "                else:\n",
    "                    data_new2.append(list(item[:max_entropy_index])+list(item[max_entropy_index+1:]))\n",
    "            if len(data_new1)==0:\n",
    "                label1=[y[-1]for y in data_new2]\n",
    "                label1_count=Counter(label1)\n",
    "                return max(label1_count.items(),key=lambda y:y[1])[0]\n",
    "            if len(data_new2)==0:\n",
    "                label2=[y[-1]for y in data_new1]\n",
    "                label2_count=Counter(label2)\n",
    "                return max(label2_count.items(),key=lambda y:y[1])[0]\n",
    "            if len(data_new1)!=0 and len(data_new2)!=0:#如果不是空集，对样本划分，并迭代\n",
    "                fea_dic_val['min_than %s'% (candidate_final)]=fea_dic_val.get('min_than %s'% (candidate_final),self.creatdisiontree(data_new1,fea_labels_new,detle))\n",
    "                fea_dic_val['max_than %s'%(candidate_final)]=fea_dic_val.get('max_than %s'%(candidate_final),self.creatdisiontree(data_new2,fea_labels_new,detle))\n",
    "                #生成节点和分叉\n",
    "                fea_dic[fea_labels[max_entropy_index]]=fea_dic.get(fea_labels[max_entropy_index],fea_dic_val)\n",
    "        return fea_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_dic_0=ID3().creatdisiontree(dataset=data1,fea_labels=np.array(range(60)).tolist(),detle=0.05)\n",
    "fea_dic_1=ID3().creatdisiontree(dataset=data1,fea_labels=np.array(range(60)).tolist(),detle=0.07)\n",
    "fea_dic_2=ID3().creatdisiontree(dataset=data1,fea_labels=np.array(range(60)).tolist(),detle=0.1)\n",
    "fea_dic_3=ID3().creatdisiontree(dataset=data1,fea_labels=np.array(range(60)).tolist(),detle=0.14)\n",
    "fea_dic_4=ID3().creatdisiontree(dataset=data1,fea_labels=np.array(range(60)).tolist(),detle=0.16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成的决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: {'min_than 0.26003119240039696': {21: {'min_than 0.7646968612616297': {2: {'min_than 0.1307490144546649': {43: {'min_than 0.048119041484153566': 'M',\n",
       "        'max_than 0.048119041484153566': 'R'}},\n",
       "      'max_than 0.1307490144546649': {3: {'min_than 0.11412268188302425': 'R',\n",
       "        'max_than 0.11412268188302425': {24: {'min_than 0.3669057377049181': 'R',\n",
       "          'max_than 0.3669057377049181': 'M'}}}}}},\n",
       "    'max_than 0.7646968612616297': {41: {'min_than 0.23492063492063497': {8: {'min_than 0.23463645787057602': 'R',\n",
       "        'max_than 0.23463645787057602': 'M'}},\n",
       "      'max_than 0.23492063492063497': {30: {'min_than 0.5552588555858311': 'M',\n",
       "        'max_than 0.5552588555858311': 'R'}}}}}},\n",
       "  'max_than 0.26003119240039696': {16: {'min_than 0.717231374987048': {34: {'min_than 0.3648869796461082': {17: {'min_than 0.09506493506493506': 'R',\n",
       "        'max_than 0.09506493506493506': 'M'}},\n",
       "      'max_than 0.3648869796461082': {17: {'min_than 0.5362597402597402': {11: {'min_than 0.42394490035169985': 'M',\n",
       "          'max_than 0.42394490035169985': {14: {'min_than 0.29777309659945833': 'M',\n",
       "            'max_than 0.29777309659945833': 'R'}}}},\n",
       "        'max_than 0.5362597402597402': {21: {'min_than 0.8305899192311625': 'R',\n",
       "          'max_than 0.8305899192311625': 'M'}}}}}},\n",
       "    'max_than 0.717231374987048': {12: {'min_than 0.6090398733266158': {26: {'min_than 0.5333018174177959': 'M',\n",
       "        'max_than 0.5333018174177959': 'R'}},\n",
       "      'max_than 0.6090398733266158': {6: {'min_than 0.5630411255411256': 'M',\n",
       "        'max_than 0.5630411255411256': 'R'}}}}}}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_dic_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: {'min_than 0.26003119240039696': {21: {'min_than 0.7646968612616297': {2: {'min_than 0.1307490144546649': {43: {'min_than 0.048119041484153566': 'M',\n",
       "        'max_than 0.048119041484153566': 'R'}},\n",
       "      'max_than 0.1307490144546649': {3: {'min_than 0.11412268188302425': 'R',\n",
       "        'max_than 0.11412268188302425': {24: {'min_than 0.3669057377049181': 'R',\n",
       "          'max_than 0.3669057377049181': 'M'}}}}}},\n",
       "    'max_than 0.7646968612616297': {41: {'min_than 0.23492063492063497': {8: {'min_than 0.23463645787057602': 'R',\n",
       "        'max_than 0.23463645787057602': 'M'}},\n",
       "      'max_than 0.23492063492063497': {30: {'min_than 0.5552588555858311': 'M',\n",
       "        'max_than 0.5552588555858311': 'R'}}}}}},\n",
       "  'max_than 0.26003119240039696': {16: {'min_than 0.717231374987048': {34: {'min_than 0.3648869796461082': {17: {'min_than 0.09506493506493506': 'R',\n",
       "        'max_than 0.09506493506493506': 'M'}},\n",
       "      'max_than 0.3648869796461082': {17: {'min_than 0.5362597402597402': {11: {'min_than 0.42394490035169985': 'M',\n",
       "          'max_than 0.42394490035169985': {14: {'min_than 0.29777309659945833': 'M',\n",
       "            'max_than 0.29777309659945833': 'R'}}}},\n",
       "        'max_than 0.5362597402597402': {21: {'min_than 0.8305899192311625': 'R',\n",
       "          'max_than 0.8305899192311625': 'M'}}}}}},\n",
       "    'max_than 0.717231374987048': {12: {'min_than 0.6090398733266158': {26: {'min_than 0.5333018174177959': 'M',\n",
       "        'max_than 0.5333018174177959': 'R'}},\n",
       "      'max_than 0.6090398733266158': {6: {'min_than 0.5630411255411256': 'M',\n",
       "        'max_than 0.5630411255411256': 'R'}}}}}}}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_dic_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: {'min_than 0.26003119240039696': {21: {'min_than 0.7646968612616297': {2: {'min_than 0.1307490144546649': {43: {'min_than 0.048119041484153566': 'M',\n",
       "        'max_than 0.048119041484153566': 'R'}},\n",
       "      'max_than 0.1307490144546649': {3: {'min_than 0.11412268188302425': 'R',\n",
       "        'max_than 0.11412268188302425': {24: {'min_than 0.3669057377049181': 'R',\n",
       "          'max_than 0.3669057377049181': 'M'}}}}}},\n",
       "    'max_than 0.7646968612616297': {41: {'min_than 0.23492063492063497': {8: {'min_than 0.23463645787057602': 'R',\n",
       "        'max_than 0.23463645787057602': 'M'}},\n",
       "      'max_than 0.23492063492063497': {30: {'min_than 0.5552588555858311': 'M',\n",
       "        'max_than 0.5552588555858311': 'R'}}}}}},\n",
       "  'max_than 0.26003119240039696': {16: {'min_than 0.717231374987048': {34: {'min_than 0.3648869796461082': {17: {'min_than 0.09506493506493506': 'R',\n",
       "        'max_than 0.09506493506493506': 'M'}},\n",
       "      'max_than 0.3648869796461082': {17: {'min_than 0.5362597402597402': {11: {'min_than 0.42394490035169985': 'M',\n",
       "          'max_than 0.42394490035169985': {14: {'min_than 0.29777309659945833': 'M',\n",
       "            'max_than 0.29777309659945833': 'R'}}}},\n",
       "        'max_than 0.5362597402597402': {21: {'min_than 0.8305899192311625': 'R',\n",
       "          'max_than 0.8305899192311625': 'M'}}}}}},\n",
       "    'max_than 0.717231374987048': {12: {'min_than 0.6090398733266158': {26: {'min_than 0.5333018174177959': 'M',\n",
       "        'max_than 0.5333018174177959': 'R'}},\n",
       "      'max_than 0.6090398733266158': {6: {'min_than 0.5630411255411256': 'M',\n",
       "        'max_than 0.5630411255411256': 'R'}}}}}}}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_dic_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: {'min_than 0.26003119240039696': {21: {'min_than 0.7646968612616297': {2: {'min_than 0.1307490144546649': {43: {'min_than 0.048119041484153566': 'M',\n",
       "        'max_than 0.048119041484153566': 'R'}},\n",
       "      'max_than 0.1307490144546649': {3: {'min_than 0.11412268188302425': 'R',\n",
       "        'max_than 0.11412268188302425': {24: {'min_than 0.3669057377049181': 'R',\n",
       "          'max_than 0.3669057377049181': 'M'}}}}}},\n",
       "    'max_than 0.7646968612616297': {41: {'min_than 0.23492063492063497': {8: {'min_than 0.23463645787057602': 'R',\n",
       "        'max_than 0.23463645787057602': 'M'}},\n",
       "      'max_than 0.23492063492063497': {30: {'min_than 0.5552588555858311': 'M',\n",
       "        'max_than 0.5552588555858311': 'R'}}}}}},\n",
       "  'max_than 0.26003119240039696': {16: {'min_than 0.717231374987048': {34: {'min_than 0.3648869796461082': {17: {'min_than 0.09506493506493506': 'R',\n",
       "        'max_than 0.09506493506493506': 'M'}},\n",
       "      'max_than 0.3648869796461082': {17: {'min_than 0.5362597402597402': {11: {'min_than 0.42394490035169985': 'M',\n",
       "          'max_than 0.42394490035169985': {14: {'min_than 0.29777309659945833': 'M',\n",
       "            'max_than 0.29777309659945833': 'R'}}}},\n",
       "        'max_than 0.5362597402597402': {21: {'min_than 0.8305899192311625': 'R',\n",
       "          'max_than 0.8305899192311625': 'M'}}}}}},\n",
       "    'max_than 0.717231374987048': {12: {'min_than 0.6090398733266158': {26: {'min_than 0.5333018174177959': 'M',\n",
       "        'max_than 0.5333018174177959': 'R'}},\n",
       "      'max_than 0.6090398733266158': {6: {'min_than 0.5630411255411256': 'M',\n",
       "        'max_than 0.5630411255411256': 'R'}}}}}}}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_dic_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: {'min_than 0.26003119240039696': {21: {'min_than 0.7646968612616297': {2: {'min_than 0.1307490144546649': {43: {'min_than 0.048119041484153566': 'M',\n",
       "        'max_than 0.048119041484153566': 'R'}},\n",
       "      'max_than 0.1307490144546649': {3: {'min_than 0.11412268188302425': 'R',\n",
       "        'max_than 0.11412268188302425': {24: {'min_than 0.3669057377049181': 'R',\n",
       "          'max_than 0.3669057377049181': 'M'}}}}}},\n",
       "    'max_than 0.7646968612616297': {41: {'min_than 0.23492063492063497': {8: {'min_than 0.23463645787057602': 'R',\n",
       "        'max_than 0.23463645787057602': 'M'}},\n",
       "      'max_than 0.23492063492063497': {30: {'min_than 0.5552588555858311': 'M',\n",
       "        'max_than 0.5552588555858311': 'R'}}}}}},\n",
       "  'max_than 0.26003119240039696': {16: {'min_than 0.717231374987048': {34: {'min_than 0.3648869796461082': {17: {'min_than 0.09506493506493506': 'R',\n",
       "        'max_than 0.09506493506493506': 'M'}},\n",
       "      'max_than 0.3648869796461082': {17: {'min_than 0.5362597402597402': {11: {'min_than 0.42394490035169985': 'M',\n",
       "          'max_than 0.42394490035169985': {14: {'min_than 0.29777309659945833': 'M',\n",
       "            'max_than 0.29777309659945833': 'R'}}}},\n",
       "        'max_than 0.5362597402597402': {21: {'min_than 0.8305899192311625': 'R',\n",
       "          'max_than 0.8305899192311625': 'M'}}}}}},\n",
       "    'max_than 0.717231374987048': {12: {'min_than 0.6090398733266158': {26: {'min_than 0.5333018174177959': 'M',\n",
       "        'max_than 0.5333018174177959': 'R'}},\n",
       "      'max_than 0.6090398733266158': {6: {'min_than 0.5630411255411256': 'M',\n",
       "        'max_than 0.5630411255411256': 'R'}}}}}}}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_dic_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tree(fea_dic,data):\n",
    "    fea_dic_keys=list(fea_dic.keys())[0]\n",
    "    fea_dic=fea_dic[fea_dic_keys]\n",
    "    \n",
    "    \n",
    "    num=data[fea_dic_keys]\n",
    "    next_node=list(fea_dic.keys())\n",
    "    num_than=float(re.findall(r\"\\d+\\.?\\d*\",next_node[0])[0])\n",
    "    if num<num_than:\n",
    "        \n",
    "        char=fea_dic[next_node[0]]\n",
    "                \n",
    "        \n",
    "        if isinstance(char,str):\n",
    "            return char\n",
    "        \n",
    "        if isinstance(char,dict):\n",
    "            return test_tree(char,data) \n",
    "    if num>=num_than:\n",
    "        \n",
    "        char=fea_dic[next_node[1]]\n",
    "       \n",
    "        if isinstance(char,str):\n",
    "\n",
    "            return char\n",
    "           \n",
    "        \n",
    "        if isinstance(char,dict):\n",
    "            return test_tree(char,data)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(fea_dic):\n",
    "    count=0\n",
    "    for i in range(50):\n",
    "\n",
    "        char=str(test_tree(fea_dic,data_test[i,:]))\n",
    "\n",
    "        if char==label_test[i]:\n",
    "            count+=1\n",
    "    print(count/50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四种参数下的正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n"
     ]
    }
   ],
   "source": [
    "test(fea_dic_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n"
     ]
    }
   ],
   "source": [
    "test(fea_dic_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n"
     ]
    }
   ],
   "source": [
    "test(fea_dic_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n"
     ]
    }
   ],
   "source": [
    "test(fea_dic_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n"
     ]
    }
   ],
   "source": [
    "test(fea_dic_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Get_train_ada(object):\n",
    "    def __init__(self,data,labels):\n",
    "        self.data=data\n",
    "        self.labels=labels\n",
    "    \n",
    "    def get_random_number(self):\n",
    "        list_ram_num=[]\n",
    "        \n",
    "        while len(list_ram_num)<70:\n",
    "            \n",
    "            num=random.randint(0,120)\n",
    "            \n",
    "            list_ram_num.append(num)\n",
    "            \n",
    "            list_ram_num=list(set(list_ram_num))\n",
    "        return np.array(list_ram_num)\n",
    "        \n",
    "    def get_Data(self):\n",
    "        \n",
    "        random_num=self.get_random_number()\n",
    "        \n",
    "        train_ran=list(range(70))\n",
    "        np.random.shuffle(train_ran)\n",
    "        data_train=self.data[random_num][train_ran]\n",
    "        label_train=self.labels[random_num][train_ran]\n",
    " \n",
    "        return data_train,label_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test,final_labels=data_test,label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_data=data_train[0:121]\n",
    "ada_labels=label_train[0:121]\n",
    "ada_datasets=np.concatenate((ada_data,ada_labels.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test,label_test=data_train[121:],label_train[121:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class forest(object):\n",
    "    def __init__(self,data,labels,test_data,labels_test,maxiters,final_test,final_labels,number,detle):\n",
    "        self.data=data\n",
    "        self.labels=labels\n",
    "        self.fea_ID=np.array(range(60)).tolist()\n",
    "        self.w=np.ones(37,)/37\n",
    "        self.alpha=np.ones(number,)/number\n",
    "        self.test_data=test_data\n",
    "        self.labels_test=labels_test\n",
    "        self.maxiters=maxiters\n",
    "        self.final_test=final_test\n",
    "        self.final_labels=final_labels\n",
    "        self.number=number\n",
    "        self.detle=detle\n",
    "        \n",
    "    \n",
    "    def get_tree(self,one_data,one_labels):\n",
    "        one_labels=one_labels.reshape(-1,1)\n",
    "        data=np.concatenate((one_data,one_labels),axis=1)\n",
    "        fea_dic=ID3().creatdisiontree(dataset=data,fea_labels=np.array(range(60)).tolist(),detle=self.detle)\n",
    "        \n",
    "        \n",
    "        return fea_dic\n",
    "    \n",
    "    def test_tree(self,fea_dic,data):\n",
    "        fea_dic_keys=list(fea_dic.keys())[0]\n",
    "        fea_dic=fea_dic[fea_dic_keys]\n",
    "\n",
    "\n",
    "        num=data[fea_dic_keys]\n",
    "        next_node=list(fea_dic.keys())\n",
    "        num_than=float(re.findall(r\"\\d+\\.?\\d*\",next_node[0])[0])\n",
    "        if num<num_than:\n",
    "\n",
    "            char=fea_dic[next_node[0]]\n",
    "\n",
    "\n",
    "            if isinstance(char,str):\n",
    "                return char\n",
    "\n",
    "            if isinstance(char,dict):\n",
    "                return test_tree(char,data) \n",
    "        if num>=num_than:\n",
    "\n",
    "            char=fea_dic[next_node[1]]\n",
    "\n",
    "            if isinstance(char,str):\n",
    "\n",
    "                return char\n",
    "\n",
    "\n",
    "            if isinstance(char,dict):\n",
    "                return test_tree(char,data)\n",
    "    \n",
    "    def count_truth(self,fea_dic):\n",
    "        \n",
    "        count=0\n",
    "        list_char=[]\n",
    "        for i in range(37):\n",
    "    \n",
    "            char=str(self.test_tree(fea_dic,self.test_data[i,:]))\n",
    "          \n",
    "            list_char.append(char)\n",
    "            if char==self.labels_test[i]:\n",
    "                count+=1\n",
    "            \n",
    "            \n",
    "        return count/37,list_char\n",
    "    \n",
    "    def get_datas(self):\n",
    "        list_data=[]\n",
    "        list_labels=[]\n",
    "        for i in range(self.number):\n",
    "            data,labels=Get_train_ada(self.data,self.labels).get_Data()\n",
    "            list_data.append(data)\n",
    "            list_labels.append(labels)\n",
    "            \n",
    "        return list_data,list_labels\n",
    "\n",
    "    def change_w(self):\n",
    "        y=copy.copy(self.labels_test)\n",
    "        y[self.labels_test=='M']=1\n",
    "        y[self.labels_test=='R']=-1\n",
    "        y=np.array(list(map(int,y)))\n",
    "        list_data,list_labels=self.get_datas()\n",
    "        trees=[]\n",
    "        for j in range(self.number):\n",
    "            fea_dic=self.get_tree(list_data[j],list_labels[j])\n",
    "            trees.append(fea_dic)\n",
    "        \n",
    "        for i in range(self.maxiters):\n",
    "            cout_lis=[]\n",
    "            list_char=[]\n",
    "            for j in range(self.number):\n",
    "                count_tru,char_arr=self.count_truth(trees[j])\n",
    "        \n",
    "                cout_lis.append(count_tru)\n",
    "                list_char.append(char_arr)\n",
    "            \n",
    "            index_min=cout_lis.index(max(cout_lis))\n",
    "            char=list_char[index_min]\n",
    "            char=np.array(char)\n",
    "            \n",
    "            index_where=np.where(char!=self.labels_test)[0]\n",
    "            \n",
    "            char[char=='M']=3\n",
    "            char[char=='R']=1\n",
    "            char=np.array(list(map(int,char)))-2\n",
    "            \n",
    "            loss=float(sum(self.w[index_where]))\n",
    "            alpha=(1/2)*log((1-loss)/loss)\n",
    "            self.alpha[index_min]=alpha\n",
    "            Z=2*np.sqrt(loss*(1-loss))\n",
    "        \n",
    "            self.w[index_where]=self.w[index_where]*np.exp(-alpha*y[index_where]*char[index_where])\n",
    "            \n",
    "        return trees\n",
    "    \n",
    "    def count_truth2(self,fea_dic):\n",
    "\n",
    "        count=0\n",
    "        list_char=[]\n",
    "        for i in range(50):\n",
    "\n",
    "            char=str(self.test_tree(fea_dic,self.final_test[i,:]))\n",
    "            list_char.append(char)\n",
    "            if char==self.final_labels[i]:\n",
    "                count+=1\n",
    "        return count/50,np.array(list_char)\n",
    "    def get_pre(self):\n",
    "        list_arr=[]\n",
    "        trees=self.change_w()\n",
    "        for i in range(self.number):\n",
    "            count,char_arr=self.count_truth2(trees[i])\n",
    "            char_arr[char_arr=='M']=3\n",
    "            char_arr[char_arr=='R']=1\n",
    "            char_arr=np.array(list(map(int,char_arr)))-2\n",
    "            list_arr.append(char_arr)\n",
    "       \n",
    "        all_=0\n",
    "        for i in range(self.number):\n",
    "            all_+=list_arr[i]*self.alpha[i]\n",
    "        all_=np.array(list(map(str,all_)))\n",
    "        all_[all_>='0']='M'\n",
    "        all_[all_<'0']='R'\n",
    "        \n",
    "        pre=sum(all_==self.final_labels)/len(self.final_labels)\n",
    "        return pre\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试正确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不同棵树下,依次为3，6，9，12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62\n"
     ]
    }
   ],
   "source": [
    "print(forest(ada_data,ada_labels,data_test,label_test,\n",
    "             maxiters=200,final_test=final_test,final_labels=final_labels,number=3,detle=0.1).get_pre())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n"
     ]
    }
   ],
   "source": [
    "print(forest(ada_data,ada_labels,data_test,label_test,\n",
    "             maxiters=200,final_test=final_test,final_labels=final_labels,number=6,detle=0.1).get_pre())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n"
     ]
    }
   ],
   "source": [
    "print(forest(ada_data,ada_labels,data_test,label_test,\n",
    "             maxiters=200,final_test=final_test,final_labels=final_labels,number=9,detle=0.1).get_pre())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n"
     ]
    }
   ],
   "source": [
    "print(forest(ada_data,ada_labels,data_test,label_test,\n",
    "             maxiters=200,final_test=final_test,final_labels=final_labels,number=12,detle=0.1).get_pre())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不同深度下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n"
     ]
    }
   ],
   "source": [
    "print(forest(ada_data,ada_labels,data_test,label_test,\n",
    "             maxiters=200,final_test=final_test,final_labels=final_labels,number=9,detle=0.1).get_pre())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n"
     ]
    }
   ],
   "source": [
    "print(forest(ada_data,ada_labels,data_test,label_test,\n",
    "             maxiters=200,final_test=final_test,final_labels=final_labels,number=9,detle=0.11).get_pre())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n"
     ]
    }
   ],
   "source": [
    "print(forest(ada_data,ada_labels,data_test,label_test\n",
    "             ,maxiters=200,final_test=final_test,final_labels=final_labels,number=9,detle=0.13).get_pre())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n"
     ]
    }
   ],
   "source": [
    "print(forest(ada_data,ada_labels,data_test,label_test,\n",
    "             maxiters=200,final_test=final_test,final_labels=final_labels,number=9,detle=0.14).get_pre())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
