{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[ 1.09398223e-01, -7.01745391e-01, -3.91475797e-01, -6.80442691e-01,\n",
    "        1.01302110e-01, -2.06758165e+00, -6.15261076e-03,  1.38641715e+00,\n",
    "       -2.16011858e+00, -4.80607837e-01, -5.36878824e-01,  6.61370993e-01,\n",
    "        9.80835080e-01,  1.00194581e-01, -1.20660122e-02, -2.92659551e-01,\n",
    "        1.90165401e+00, -3.55604917e-01, -3.41223150e-01,  9.20889914e-01,\n",
    "       -4.10751253e-01, -3.04967910e-01,  4.59801555e-01, -9.15719122e-02,\n",
    "        8.23659301e-02,  6.73895359e-01, -7.51458883e-01,  6.69990301e-01,\n",
    "       -2.90337682e+00, -1.07552361e+00,  1.79552543e+00, -1.81808543e+00,\n",
    "        1.68375921e+00,  3.00740331e-01,  1.24897063e+00,  1.54214501e-02,\n",
    "       -2.21818113e+00, -6.40897080e-02, -8.21697235e-01, -1.34972692e-01,\n",
    "        2.34940362e+00, -7.03830421e-01,  5.06786704e-01, -6.99196637e-01,\n",
    "       -1.26937437e+00, -2.52861857e-01,  1.63582432e+00, -7.96311975e-01,\n",
    "       -3.15868974e-01, -5.67130595e-02, -9.54037011e-02, -1.56947002e-01,\n",
    "       -4.32539701e-01,  1.21812963e+00,  2.44811296e-01,  1.06517493e-03,\n",
    "        5.37360191e-01, -3.14026233e-03, -4.55410331e-01,  1.50040537e-01,\n",
    "       -1.65251696e+00,  8.37693751e-01, -8.84405971e-01, -8.05317521e-01,\n",
    "        1.51757407e+00, -1.44158435e+00, -2.14658093e+00,  7.56792873e-02,\n",
    "        1.08882594e+00,  7.18542516e-01,  9.70552444e-01, -1.62083730e-01,\n",
    "        2.36011427e-02, -3.14742517e+00, -1.59132302e+00, -3.47380936e-01,\n",
    "        1.08195893e-01, -1.51989698e-01, -2.19788939e-01,  1.27668834e+00,\n",
    "        1.03366423e+00, -1.93199742e+00, -6.66437522e-02, -4.05270517e-01,\n",
    "        8.54746938e-01,  1.92735076e+00, -6.11654878e-01,  2.68646866e-01,\n",
    "       -6.33371532e-01,  3.76523793e-01,  7.92135119e-01, -1.49863124e+00,\n",
    "       -4.46011536e-02,  4.74136055e-01,  1.02864766e+00,  8.89996469e-01,\n",
    "        6.75564468e-01, -1.30954355e-01,  4.94244576e-01,  7.45899558e-01,\n",
    "       -1.56613335e-01,  1.36730075e+00,  1.68628380e-01,  3.53314658e-03,\n",
    "        9.03990090e-01,  1.40195444e-01,  9.85414833e-02,  4.19275254e-01,\n",
    "       -3.36481519e-02,  2.45326549e-01,  3.54516953e-02, -1.18209696e+00,\n",
    "       -8.56581450e-01, -7.61776924e-01, -1.38177598e+00, -2.66133845e-01,\n",
    "        1.45023775e+00,  1.41912496e+00,  1.44648060e-01, -3.14437523e-02,\n",
    "        6.65680051e-01,  3.58196586e-01, -3.91108215e-01, -5.19516408e-01,\n",
    "        1.32320571e+00,  5.18085122e-01,  1.75068307e+00, -1.03100896e-01,\n",
    "        1.83369660e+00, -3.15227365e+00, -1.65771887e-01,  1.35008901e-01,\n",
    "        9.73028541e-01,  9.16363239e-01,  6.70804977e-02,  1.64290369e+00,\n",
    "        1.10678589e+00,  7.80407131e-01, -7.64281154e-02,  9.81125057e-01,\n",
    "        1.15349877e+00, -1.07952583e+00,  4.37276691e-01, -9.56526920e-02,\n",
    "       -8.10703993e-01,  6.46177649e-01, -2.62691259e-01, -3.44538599e-01,\n",
    "       -3.27624917e-01, -1.30278456e+00,  3.30004036e-01, -1.46936297e+00,\n",
    "        8.58642533e-02,  2.49484509e-01,  1.05241692e+00,  2.04514652e-01,\n",
    "        1.08832610e+00, -1.73757032e-01, -2.77286887e-01,  9.67025936e-01,\n",
    "       -2.05639100e+00, -8.07983875e-01,  1.58234465e+00,  5.64972997e-01,\n",
    "        5.91350913e-01, -1.40839130e-01, -5.42346776e-01,  1.33135033e+00,\n",
    "       -2.24199295e-01, -4.79004979e-01,  6.44344151e-01, -1.65611947e+00,\n",
    "       -4.11438584e-01, -1.14152487e-02, -1.81588328e+00, -6.95155025e-01,\n",
    "       -2.41588354e-01,  1.52799892e+00, -1.07857645e+00, -2.46833473e-01,\n",
    "       -7.85873115e-01,  1.19508058e-01, -7.70763695e-01,  2.64164233e+00,\n",
    "        2.96800613e-01, -2.86061436e-01,  1.89369798e+00,  5.50864816e-01,\n",
    "       -7.57534742e-01,  8.85300413e-02, -3.93872231e-01,  1.30517602e+00,\n",
    "       -2.31828284e+00, -1.59819078e+00,  5.88336825e-01, -1.12500146e-01,\n",
    "       -5.14462173e-01,  1.05639309e-01,  8.68221879e-01, -2.21772552e+00,\n",
    "        8.25944364e-01, -4.18995500e-01, -4.38051373e-01, -1.35572326e+00,\n",
    "        9.16148365e-01,  1.13186345e-01,  1.31754375e+00,  6.73261702e-01,\n",
    "       -1.49814993e-01, -8.13537121e-01, -5.16351819e-01, -3.73705357e-01,\n",
    "       -1.99787974e-01, -1.58680692e-01, -8.34456921e-01,  2.34511018e+00,\n",
    "        9.11160409e-02, -6.41909719e-01,  8.30103934e-01, -2.39636656e-02,\n",
    "       -1.19645226e+00,  8.12078118e-01,  5.57315767e-01, -2.54300666e+00,\n",
    "        1.73908964e-01,  8.98634851e-01, -1.32860139e-01, -1.89663732e+00,\n",
    "       -3.11678737e-01, -1.30957112e-01,  2.52645612e-01, -2.09982902e-01,\n",
    "        2.66717339e+00,  3.40309769e-01,  4.76272643e-01, -4.87283617e-01,\n",
    "       -3.59700948e-01, -1.54874396e+00,  6.54738843e-01,  6.31636143e-01,\n",
    "        6.61850393e-01,  1.30487251e+00, -2.40038246e-01, -1.01502395e+00,\n",
    "        2.06906533e+00,  2.23190635e-02, -8.87865841e-01, -2.24324360e-01,\n",
    "        5.66155493e-01, -1.11572206e+00,  4.65975523e-01, -1.04832935e+00,\n",
    "        1.58024025e+00,  1.57934809e+00,  6.82842553e-01,  9.98936415e-01]\n",
    "eps=paddle.to_tensor(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(input_channels,filters):\n",
    "    block=paddle.nn.Sequential(paddle.fluid.dygraph.Conv2D(input_channels,filters,filter_size=3,stride=2,padding=1),\n",
    "                              paddle.nn.layer.InstanceNorm2D(filters),\n",
    "                              paddle.nn.LeakyReLU())\n",
    "   \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Encoder(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Image_Encoder,self).__init__()\n",
    "        \n",
    "        self.encoder_block1=encoder_block(3,64)\n",
    "        self.encoder_block2=encoder_block(64,128)\n",
    "        self.encoder_block3=encoder_block(128,256)\n",
    "        self.encoder_block4=encoder_block(256,512)\n",
    "        self.encoder_block5=encoder_block(512,512)\n",
    "        self.encoder_block6=encoder_block(512,512)\n",
    "        self.layer1=paddle.nn.Linear(8192,256)\n",
    "        self.layer2=paddle.nn.Linear(8192,256)\n",
    "    def forward(self,x):\n",
    "        x=self.encoder_block1(x)\n",
    "        x=self.encoder_block2(x)\n",
    "        x=self.encoder_block3(x)\n",
    "        x=self.encoder_block4(x)\n",
    "        x=self.encoder_block5(x)\n",
    "        x=self.encoder_block6(x)\n",
    "        x=paddle.nn.Flatten()(x)\n",
    "        mean=self.layer1(x)\n",
    "        var=self.layer2(x)\n",
    "        \n",
    "        return mean,var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Spade(x,segmap):\n",
    "    c=paddle.shape(x).numpy()[1]\n",
    "    w=paddle.shape(x).numpy()[2]\n",
    "    h=paddle.shape(x).numpy()[3]\n",
    "    x=paddle.nn.layer.BatchNorm2D(c)(x)\n",
    "    segmap=paddle.fluid.layers.image_resize(segmap,out_shape=[w,h])\n",
    "    segmap=paddle.fluid.dygraph.Conv2D(3,128,filter_size=3,stride=1,padding=1)(segmap)\n",
    "    segmap=paddle.nn.layer.ReLU()(segmap)\n",
    "    \n",
    "    gamma=paddle.fluid.dygraph.Conv2D(128,c,stride=1,filter_size=3,padding=1)(segmap)\n",
    "    beta=paddle.fluid.dygraph.Conv2D(128,c,stride=1,filter_size=3,padding=1)(segmap)\n",
    "    \n",
    "    return (gamma+1)*x+beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spade_ResBIK(paddle.nn.Layer):\n",
    "    def __init__(self,input_channels,filters):\n",
    "        super(Spade_ResBIK,self).__init__()\n",
    "        \n",
    "        self.layer1=paddle.fluid.dygraph.Conv2D(input_channels,filters,filter_size=3,stride=1,padding=1)\n",
    "        \n",
    "        self.layer2=paddle.fluid.dygraph.Conv2D(filters,filters,filter_size=3,stride=1,padding=1)\n",
    "        \n",
    "        self.layer3=paddle.fluid.dygraph.Conv2D(input_channels,filters,filter_size=3,stride=1,padding=1)\n",
    "    def forward(self,x,segmap):\n",
    "        \n",
    "        x1=Spade(x,segmap)\n",
    "        x1=paddle.nn.layer.LeakyReLU()(x1)\n",
    "        x1=self.layer1(x1)\n",
    "\n",
    "        x1=Spade(x1,segmap)\n",
    "        x1=paddle.nn.layer.LeakyReLU()(x1)\n",
    "        x1=self.layer2(x1)\n",
    "        \n",
    "        x=Spade(x,segmap)\n",
    "        x=paddle.nn.layer.LeakyReLU()(x)\n",
    "        x=self.layer3(x)\n",
    "        \n",
    "        return x+x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANGenerator(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(GANGenerator,self).__init__()\n",
    "        \n",
    "        self.layer1=paddle.nn.layer.Linear(256,16384)\n",
    "        \n",
    "        self.Spade_ResBIK1=Spade_ResBIK(1024,1024)\n",
    "        self.Spade_ResBIK2=Spade_ResBIK(1024,1024)\n",
    "        self.Spade_ResBIK3=Spade_ResBIK(1024,1024)\n",
    "        self.Spade_ResBIK4=Spade_ResBIK(1024,512)\n",
    "        self.Spade_ResBIK5=Spade_ResBIK(512,256)\n",
    "        self.Spade_ResBIK6=Spade_ResBIK(256,128)\n",
    "        self.Spade_ResBIK7=Spade_ResBIK(128,64)\n",
    "        \n",
    "        self.conv_final=paddle.fluid.dygraph.Conv2D(64,3,stride=1,filter_size=3,padding=1)\n",
    "        \n",
    "    def forward(self,mean,var,segmap):\n",
    "        x=paddle.exp(0.5*var)\n",
    "        x=x*eps+mean\n",
    "        \n",
    "        x1=self.layer1(x)\n",
    "        x1=paddle.reshape(x1,[-1,1024,4,4])\n",
    "        \n",
    "        x=self.Spade_ResBIK1(x1,segmap)\n",
    "        x=paddle.nn.layer.Upsample(scale_factor=2)(x)\n",
    "        \n",
    "        x=self.Spade_ResBIK2(x,segmap)\n",
    "        x=paddle.nn.layer.Upsample(scale_factor=2)(x)\n",
    "        \n",
    "        x=self.Spade_ResBIK3(x,segmap)\n",
    "        x=paddle.nn.layer.Upsample(scale_factor=2)(x)\n",
    "        \n",
    "        x=self.Spade_ResBIK4(x,segmap)\n",
    "        x=paddle.nn.layer.Upsample(scale_factor=2)(x)\n",
    "        \n",
    "        x=self.Spade_ResBIK5(x,segmap)\n",
    "        x=paddle.nn.layer.Upsample(scale_factor=2)(x)\n",
    "        \n",
    "        x=self.Spade_ResBIK6(x,segmap)\n",
    "        x=paddle.nn.layer.Upsample(scale_factor=2)(x)\n",
    "        \n",
    "        x=self.Spade_ResBIK6(x,segmap)\n",
    "        x=self.conv_final(x)\n",
    "        \n",
    "        x=paddle.nn.layer.Tanh()(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paddle.summary(GANGenerator(),[(256),(256),(64,3,256,256)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "import keras_contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_block(filters):\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    \n",
    "    block=tf.keras.Sequential()\n",
    "    block.add(tf.keras.layers.Conv2D(filters,4,strides=2,padding='same',kernel_initializer=initializer,use_bias=False))\n",
    "    block.add(keras_contrib.layers.InstanceNormalization())\n",
    "    block.add(tf.keras.layers.LeakyReLU())\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    inputs=tf.keras.layers.Input(shape=[256,256,3])\n",
    "    inputs2=tf.keras.layers.Input(shape=[256,256,3])\n",
    "    x=tf.keras.layers.concatenate([inputs,inputs2])\n",
    "    \n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    \n",
    "    dis_blocks=[\n",
    "        dis_block(64),\n",
    "        dis_block(128),\n",
    "        dis_block(256),\n",
    "    ]\n",
    "    for block in dis_blocks:\n",
    "        x=block(x)\n",
    "    x=tf.keras.layers.Conv2D(256,2,strides=1,padding='valid',kernel_initializer=initializer,use_bias=False)(x)\n",
    "    x=keras_contrib.layers.InstanceNormalization()(x)\n",
    "    x=tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    x=tf.keras.layers.Conv2D(256,2,strides=1,padding='valid',kernel_initializer=initializer,use_bias=False)(x)\n",
    "    x1=tf.nn.sigmoid(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=[inputs,inputs2],outputs=x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Discriminator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_block(input_channels,filters):\n",
    "    \n",
    "    block=paddle.nn.Sequential(paddle.fluid.dygraph.Conv2D(input_channels,filters,filter_size=4,stride=2,padding=1),\n",
    "                              paddle.nn.layer.InstanceNorm2D(filters),\n",
    "                              paddle.nn.layer.LeakyReLU())\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        \n",
    "        self.dis_block1=dis_block(6,64)\n",
    "        self.dis_block2=dis_block(64,128)\n",
    "        self.dis_block3=dis_block(128,256)\n",
    "\n",
    "    def forward(self,x,segmap):\n",
    "        x=paddle.concat([x,segmap],axis=1)\n",
    "\n",
    "        x=self.dis_block1(x)\n",
    "        x=self.dis_block2(x)\n",
    "        x=self.dis_block3(x)\n",
    "        \n",
    "        x=paddle.fluid.dygraph.Conv2D(256,512,filter_size=4,stride=1,padding=1)(x)\n",
    "        x=paddle.nn.layer.InstanceNorm2D(512)(x)\n",
    "        x=paddle.nn.layer.LeakyReLU()(x)\n",
    "        \n",
    "        x=paddle.fluid.dygraph.Conv2D(512,1,stride=1,filter_size=4,padding=1)(x)\n",
    "        x=paddle.nn.layer.Sigmoid()(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paddle.summary(Discriminator(),[(1,3,256,256),(1,3,256,256)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.applications.VGG19(input_shape=(256,256,3),weights='imagenet',include_top=False)\n",
    "model.trainable=False\n",
    "slice1=tf.keras.Sequential()\n",
    "slice2=tf.keras.Sequential()\n",
    "slice3=tf.keras.Sequential()\n",
    "slice4=tf.keras.Sequential()\n",
    "slice5=tf.keras.Sequential()\n",
    "\n",
    "for i in range(4):\n",
    "    slice1.add(model.layers[i])\n",
    "for i in range(4,7):\n",
    "    slice2.add(model.layers[i])\n",
    "for i in range(7,12):\n",
    "    slice3.add(model.layers[i])\n",
    "for i in range(12,17):\n",
    "    slice4.add(model.layers[i])\n",
    "for i in range(17,22):\n",
    "    slice5.add(model.layers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16=paddle.vision.models.vgg16(pretrained=True).features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16=paddle.vision.models.vgg16(pretrained=True).features\n",
    "slice1=paddle.nn.Sequential()\n",
    "slice2=paddle.nn.Sequential()\n",
    "slice3=paddle.nn.Sequential()\n",
    "slice4=paddle.nn.Sequential()\n",
    "slice5=paddle.nn.Sequential()\n",
    "\n",
    "for i in range(0,5):\n",
    "    slice1.add_sublayer(sublayer=vgg16[i],name=str(i))\n",
    "for i in range(5,10):\n",
    "    slice2.add_sublayer(sublayer=vgg16[i],name=str(i))\n",
    "for i in range(10,17):\n",
    "    slice3.add_sublayer(sublayer=vgg16[i],name=str(i))\n",
    "for i in range(17,24):\n",
    "    slice4.add_sublayer(sublayer=vgg16[i],name=str(i))\n",
    "for i in range(24,31):\n",
    "    slice5.add_sublayer(sublayer=vgg16[i],name=str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg19_input(image):\n",
    "    x1=slice1(image)\n",
    "    x2=slice2(x1)\n",
    "    x3=slice3(x2)\n",
    "    x4=slice4(x3)\n",
    "    x5=slice5(x4)\n",
    "    return [x1,x2,x3,x4,x5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = paddle.optimizer.Adam(parameters=,2e-4,beta1=0.5)\n",
    "discriminator_optimizer = paddle.optimizer.Adam(2e-4,beta1=0.5)\n",
    "encoder_optimizer=paddle.optimizer.Adam(2e-4,beta1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(input_image, target, epoch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape,tf.GradientTape() as encoder_tape:\n",
    "        style=encoder(target,training=True)\n",
    "        gen_output = generator([input_image,style], training=True)\n",
    "\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "        gen_total_loss,gen_l1_loss = generator_loss(target,disc_generated_output,gen_output)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "    encoder_gradients=encoder_tape.gradient(gen_l1_loss,\n",
    "                                            encoder.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))\n",
    "    encoder_optimizer.apply_gradients(zip(encoder_gradients,encoder.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
