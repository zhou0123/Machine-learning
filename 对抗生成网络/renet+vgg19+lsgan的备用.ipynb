{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(filters,size):\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    block=tf.keras.Sequential()\n",
    "    block.add(tf.keras.layers.ZeroPadding2D(1))\n",
    "    block.add(tf.keras.layers.Conv2D(filters,size,strides=1,padding='valid',kernel_initializer=initializer,use_bias=False))\n",
    "    block.add(tf.keras.layers.BatchNormalization())\n",
    "    block.add(tf.keras.layers.LeakyReLU())\n",
    "    block.add(tf.keras.layers.ZeroPadding2D(1))\n",
    "    block.add(tf.keras.layers.Conv2D(filters,size,strides=1,padding='valid',kernel_initializer=initializer,use_bias=False))\n",
    "    block.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "          tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                                 kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                        padding='same',\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    inputs=tf.keras.layers.Input(shape=[256,256,3])#标签\n",
    "    \n",
    "    residual_blocks=[\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3)\n",
    "    ]\n",
    "    \n",
    "    x1=inputs\n",
    "    x1=tf.keras.layers.ZeroPadding2D(3)(x1)\n",
    "    x1=tf.keras.layers.Conv2D(64,7,strides=1,padding='valid',kernel_initializer=initializer,use_bias=False)(x1)\n",
    "    x1=tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1=tf.keras.layers.LeakyReLU()(x1)\n",
    "    \n",
    "    #下采样 此时输入为（256，256，64）\n",
    "    x1=tf.keras.layers.Conv2D(128,3,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x1)#(128,128,128)\n",
    "    x1=tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1_1=tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1=tf.keras.layers.Conv2D(256,3,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x1_1)#(64,64,256)\n",
    "    x1=tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1_2=tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1=tf.keras.layers.Conv2D(512,3,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x1_2)#(32,32,512)\n",
    "    x1=tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1=tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1_3=x1\n",
    "    \n",
    "    #残差\n",
    "    for block in residual_blocks:\n",
    "        x11=block(x1)\n",
    "        x1=tf.add(x1,x11)\n",
    "    #上采样此时（32，32，256）\n",
    "    x1=tf.keras.layers.Concatenate()([x1_3, x1])\n",
    "    x1=tf.keras.layers.Conv2DTranspose(256,3,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x1)#(64,64,256)\n",
    "    x1=tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1=tf.keras.layers.LeakyReLU()(x1)\n",
    "    \n",
    "    x1=tf.keras.layers.Concatenate()([x1_2, x1])\n",
    "    x1=tf.keras.layers.Conv2DTranspose(128,3,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x1)#(128,128,128)\n",
    "    x1=tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1=tf.keras.layers.LeakyReLU()(x1)\n",
    "    \n",
    "    x1=tf.keras.layers.Concatenate()([x1_1, x1])\n",
    "    x1=tf.keras.layers.Conv2DTranspose(64,3,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x1)#(256,256,64)\n",
    "    x1=tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1=tf.keras.layers.LeakyReLU()(x1)\n",
    "    \n",
    "    x1=tf.keras.layers.Conv2D(3,7,strides=1,padding='same',kernel_initializer=initializer,use_bias=False,activation='tanh')(x1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs,outputs=x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "    tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n",
    "\n",
    "    down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n",
    "    down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n",
    "    down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                  kernel_initializer=initializer,\n",
    "                                  use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                  kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
