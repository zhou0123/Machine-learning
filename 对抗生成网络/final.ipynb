{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "import keras_contrib\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import zipfile\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(image_file):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "\n",
    "    w = tf.shape(image)[1]\n",
    "\n",
    "    w = w // 2\n",
    "    real_image = image[:, w:, :]\n",
    "    input_image = image[:, :w, :]\n",
    "\n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    real_image = tf.cast(real_image, tf.float32)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(input_image, real_image, height, width):\n",
    "    input_image = tf.image.resize(input_image, [height, width],\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    real_image = tf.image.resize(real_image, [height, width],\n",
    "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目标尺寸\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "def random_crop(input_image, real_image):\n",
    "    stacked_image = tf.stack([input_image, real_image], axis=0)\n",
    "    cropped_image = tf.image.random_crop(\n",
    "      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "    return cropped_image[0], cropped_image[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_jitter(input_image, real_image):\n",
    "    # resizing to 286 x 286 x 3\n",
    "    input_image, real_image = resize(input_image, real_image, 286, 286)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    input_image, real_image = random_crop(input_image, real_image)\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        # random mirroring\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        real_image = tf.image.flip_left_right(real_image)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the images to [-1, 1]\n",
    "def normalize(input_image, real_image):\n",
    "    input_image = (input_image / 127.5) - 1\n",
    "    real_image = (real_image / 127.5) - 1\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_train(image_file):\n",
    "    input_image, real_image = load(image_file)\n",
    "    input_image, real_image = random_jitter(input_image, real_image)\n",
    "    input_image, real_image = normalize(input_image, real_image)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_test(image_file):\n",
    "    input_image, real_image = load(image_file)\n",
    "    input_image, real_image = resize(input_image, real_image,\n",
    "                                   IMG_HEIGHT, IMG_WIDTH)\n",
    "    input_image, real_image = normalize(input_image, real_image)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 400\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "train_dataset = tf.data.Dataset.list_files('./data_coast/'+'*.jpg')\n",
    "train_dataset = train_dataset.map(load_image_train,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.list_files('./test_coast/'+'*.jpg')\n",
    "test_dataset = test_dataset.map(load_image_test)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(filters):\n",
    "    initialiter=tf.random_normal_initializer(0,0.02)\n",
    "    \n",
    "    block=tf.keras.Sequential()\n",
    "    block.add(tf.keras.layers.Conv2D(filters,3,strides=2,padding='same',kernel_initializer=initialiter,use_bias=False))\n",
    "    block.add(keras_contrib.layers.InstanceNormalization())\n",
    "    block.add(tf.keras.layers.LeakyReLU())\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_Encoder():\n",
    "    inputs=tf.keras.layers.Input(shape=[256,256,3])\n",
    "    #风格编码\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    encoder_blocks=[\n",
    "        encoder_block(64),\n",
    "        encoder_block(128),\n",
    "        encoder_block(256),\n",
    "        encoder_block(512),\n",
    "        encoder_block(512),\n",
    "        encoder_block(512)\n",
    "    ]\n",
    "    x=inputs\n",
    "    for block in encoder_blocks:\n",
    "        x=block(x)\n",
    "    x=tf.keras.layers.Flatten()(x)\n",
    "    \n",
    "    x1=tf.keras.layers.Dense(256)(x)\n",
    "    x2=tf.keras.layers.Dense(256)(x)\n",
    "    \n",
    "    std=tf.exp(x2*0.5)\n",
    "    eps=tf.random.normal(tf.shape(x2))\n",
    "    result=eps*std+x1\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs,outputs=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "          tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                                 kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                        padding='same',\n",
    "                                        kernel_initializer=initializer,\n",
    "                                        use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
    "    inputs2=tf.keras.layers.Input(shape=[256])\n",
    "    x1=inputs\n",
    "    x2=inputs2\n",
    "    \n",
    "    x2=tf.keras.layers.Flatten()(x2)\n",
    "    x2=tf.keras.layers.Dense(16384)(x2)\n",
    "    x2=tf.reshape(x2,[-1,64,64,4])\n",
    "    x2=tf.keras.layers.Conv2DTranspose(3,7,strides=4,padding='same',kernel_initializer=initializer,use_bias=False)(x2)\n",
    "    x2=tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2=tf.keras.layers.LeakyReLU()(x2)#256,256,3\n",
    "    \n",
    "    x2=tf.keras.layers.Conv2D(128,3,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(x2)\n",
    "    x2=tf.keras.layers.ReLU()(x2)\n",
    "    gamma=tf.keras.layers.Conv2D(3,3,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(x2)\n",
    "    beta=tf.keras.layers.Conv2D(3,3,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(x2)\n",
    "    x=gamma*x1+beta\n",
    "    \n",
    "    x=tf.keras.layers.BatchNormalization()(x)\n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "        downsample(128, 4), # (bs, 64, 64, 128)\n",
    "        downsample(256, 4), # (bs, 32, 32, 256)\n",
    "        downsample(512, 4), # (bs, 16, 16, 512)\n",
    "        downsample(512, 4), # (bs, 8, 8, 512)\n",
    "        downsample(512, 4), # (bs, 4, 4, 512)\n",
    "        downsample(512, 4), # (bs, 2, 2, 512)\n",
    "        downsample(512, 4), # (bs, 1, 1, 512)\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 512)+(bs, 2, 2, 512)=(bs, 2, 2, 1024)\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "        upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "        upsample(512, 4), # (bs, 16, 16, 1024)\n",
    "        upsample(256, 4), # (bs, 32, 32, 512)\n",
    "        upsample(128, 4), # (bs, 64, 64, 256)\n",
    "        upsample(64, 4), # (bs, 128, 128, 128)\n",
    "    ]\n",
    "\n",
    "    \n",
    "    last = tf.keras.layers.Conv2DTranspose(3, 4,\n",
    "                                           strides=2,\n",
    "                                           padding='same',\n",
    "                                           kernel_initializer=initializer,\n",
    "                                           activation='tanh') # (bs, 256, 256, 3)\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)  # 第一个x是(bs, 1, 1, 512)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs,inputs2], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_block(filters):\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    \n",
    "    block=tf.keras.Sequential()\n",
    "    block.add(tf.keras.layers.Conv2D(filters,4,strides=2,padding='same',kernel_initializer=initializer,use_bias=False))\n",
    "    block.add(keras_contrib.layers.InstanceNormalization())\n",
    "    block.add(tf.keras.layers.LeakyReLU())\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    inputs=tf.keras.layers.Input(shape=[256,256,3])\n",
    "    inputs2=tf.keras.layers.Input(shape=[256,256,3])\n",
    "    x=tf.keras.layers.concatenate([inputs,inputs2])\n",
    "    \n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    \n",
    "    dis_blocks=[\n",
    "        dis_block(64),\n",
    "        dis_block(128),\n",
    "        dis_block(256),\n",
    "    ]\n",
    "    for block in dis_blocks:\n",
    "        x=block(x)\n",
    "    x=tf.keras.layers.Conv2D(512,2,strides=1,padding='valid',kernel_initializer=initializer,use_bias=False)(x)\n",
    "    x=keras_contrib.layers.InstanceNormalization()(x)\n",
    "    x=tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    x=tf.keras.layers.Conv2D(512,2,strides=1,padding='valid',kernel_initializer=initializer,use_bias=False)(x)\n",
    "    x1=tf.nn.sigmoid(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=[inputs,inputs2],outputs=x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Discriminator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg19():\n",
    "    inputs=tf.keras.layers.Input([256,256,3])\n",
    "    x=inputs\n",
    "    model=tf.keras.applications.VGG19(input_shape=(256,256,3),weights='imagenet',include_top=False)\n",
    "    model.trainable=False\n",
    "    slice1=tf.keras.Sequential()\n",
    "    slice2=tf.keras.Sequential()\n",
    "    slice3=tf.keras.Sequential()\n",
    "    slice4=tf.keras.Sequential()\n",
    "    slice5=tf.keras.Sequential()\n",
    "    \n",
    "    for i in range(4):\n",
    "        slice1.add(model.layers[i])\n",
    "    for i in range(4,7):\n",
    "        slice2.add(model.layers[i])\n",
    "    for i in range(7,12):\n",
    "        slice3.add(model.layers[i])\n",
    "    for i in range(12,17):\n",
    "        slice4.add(model.layers[i])\n",
    "    for i in range(17,22):\n",
    "        slice5.add(model.layers[i])\n",
    "    \n",
    "    x1=slice1(x)\n",
    "    x2=slice2(x1)\n",
    "    x3=slice3(x2)\n",
    "    x4=slice4(x3)\n",
    "    x5=slice5(x4)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs,outputs=[x1,x2,x3,x4,x5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator_loss(target,gen_dis_image,gen_image):#gen_image:(512,512,3) \n",
    "    gan_loss=loss_object(tf.ones_like(gen_dis_image),gen_dis_image)\n",
    "    \n",
    "    weight=[1/32,1/16,1/8,1/4,1]\n",
    "    x_1=vgg19()(gen_image)\n",
    "    x_11=vgg19()(target)\n",
    "    l1_loss=0\n",
    "    for i in range(len(x_1)):\n",
    "        l1_loss=l1_loss+weight[i]*tf.reduce_mean(tf.abs(x_1[i]-x_11[i]))\n",
    "    total_gen_loss=gan_loss+LAMBDA*l1_loss\n",
    "    \n",
    "    return total_gen_loss,l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator_loss(target_dis,gen_dis_image):\n",
    "    \n",
    "    real_loss=loss_object(tf.ones_like(target_dis),target_dis)\n",
    "    generated_loss=loss_object(tf.zeros_like(gen_dis_image),gen_dis_image)\n",
    "    \n",
    "    total_dis_loss=real_loss+generated_loss\n",
    "    return total_dis_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 100\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "encoder_optimizer=tf.keras.optimizers.Adam(2e-4,beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator=Generator()\n",
    "discriminator=Discriminator()\n",
    "style_encoder=Image_Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(input_image, target, epoch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape,tf.GradientTape() as style_tape:\n",
    "        style=style_encoder(target,training=True)\n",
    "        gen_output = generator([input_image,style], training=True)\n",
    "\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "        gen_total_loss,gen_l1_loss = Generator_loss(target, disc_generated_output, gen_output)\n",
    "        disc_loss = Discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "    style_gradients=style_tape.gradient(gen_l1_loss,\n",
    "                                        style_encoder.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))\n",
    "    encoder_optimizer.apply_gradients(zip(style_gradients,\n",
    "                                         style_encoder.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model1,model2, test_input, target):\n",
    "    style_encoder=model1(target,training=True)\n",
    "    prediction = model2([test_input,style_encoder], training=True)\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    display_list = [test_input[0], target[0], prediction[0]]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_ds, epochs, test_ds):\n",
    "    num=len(train_ds.enumerate())\n",
    "    for epoch in range(epochs):\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        for example_input, example_target in test_ds.take(1):\n",
    "            generate_images(Image_Encoder(),Generator(), example_input, example_target)\n",
    "        #print(\"Epoch: \", epoch)\n",
    "        print(\"\\r总进度完成%.2f %%\" % (epoch *100 /epochs), end=\"\")\n",
    "        print()\n",
    "        # Train\n",
    "        for n, (input_image, target) in train_ds.enumerate():\n",
    "            print(\"\\r子进度完成%.2f %%\" % (n *100 /num), end=\"\")\n",
    "            time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            if time[11:13]=='00':\n",
    "                tf.saved_model.save(Generator(),'./Generator_coast.h5')\n",
    "                tf.saved_model.save(Discriminator(),'./Discriminator_coast.h5')\n",
    "                tf.saved_model.save(Image_Encoder(),'./Image_Encoder_coast.h5')\n",
    "                print(epoch,n)\n",
    "                    \n",
    "\n",
    "            train_step(input_image, target, epoch)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "fit(train_dataset, EPOCHS, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
