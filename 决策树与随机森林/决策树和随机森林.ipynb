{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "x=pd.read_csv(r'C:\\Users\\zhou\\Desktop\\diabetes.csv',encoding='UTF-8')\n",
    "x_array=np.array(x).tolist()\n",
    "dataset=x_array[:500]\n",
    "dataset1=x_array[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from graphviz import Digraph\n",
    "class DecisionTree(object):\n",
    "    def __init__(self,algor=None,detla=0.01,root='0'):\n",
    "        self.algor=algor\n",
    "        self.detla=detla\n",
    "        self.root=root\n",
    "    #计算熵值\n",
    "    def cal_entropy(self,labels):\n",
    "        entropy=0.0\n",
    "        dic_1={}#计算每种标签出现的此数\n",
    "        for item in labels:\n",
    "            dic_1[item]=dic_1.get(item,0)+1\n",
    "        for itemN in dic_1:#计算每个标签占的比率\n",
    "            prod=dic_1[itemN]/len(labels)#概率\n",
    "            entropy-=prod*log(prod,2)#熵值\n",
    "        return entropy\n",
    "    #计算给定特征的各种划分下的最小熵值\n",
    "    def feaX_entropy(self,dataset,i):\n",
    "        entropy=0.0\n",
    "        feaX_labels=[[x[i],x[-1]] for x in dataset]#将待选择的特征与标签选出\n",
    "        feaX=[x[i] for x in dataset]\n",
    "        def takefirst(elem):\n",
    "            return elem[0]\n",
    "        feaX_labels.sort(key=takefirst)\n",
    "        feaX.sort()\n",
    "        candidate=[]#分割值的候选处\n",
    "        labels=[]\n",
    "        labels1=[]\n",
    "        entropy_list=[]\n",
    "        for i in range(len(feaX)-1):\n",
    "            candidate.append((feaX[i]+feaX[i+1])/2)\n",
    "        for candidate_sample in candidate:#计算每个分割值对应下的熵\n",
    "            count=0\n",
    "            for feaX_labels_sample in feaX_labels:\n",
    "                if candidate_sample<=feaX_labels_sample[0] :\n",
    "                    count+=1\n",
    "                    labels.append(feaX_labels_sample[-1])\n",
    "                else:\n",
    "                    labels1.append(feaX_labels_sample[-1])\n",
    "            entropy=count/len(feaX)*self.cal_entropy(labels)+(len(feaX)-count)/len(feaX)*self.cal_entropy(labels1)\n",
    "            entropy_list.append(entropy)#收成列表\n",
    "            #返回最小熵值，索引，和分割值\n",
    "        return min(entropy_list),entropy_list.index(min(entropy_list)),candidate[entropy_list.index(min(entropy_list))]\n",
    "    def _sub_plot(self,dot,tree,inc):\n",
    "        first_label=list(tree.keys())[0]#找到迭代后的字典的keys\n",
    "        tree_next=tree[first_label]#找到keys下的分叉的标志\n",
    "        for i in tree_next.keys():\n",
    "            if isinstance(tree[first_label][i],dict):#判断分叉下的种类，如果是字典则继续迭代\n",
    "                self.root=str(int(self.root)+1)\n",
    "                dot.node(self.root,list(tree[first_label][i].keys())[0])\n",
    "                dot.edge(inc,self.root,str(i))\n",
    "                self._sub_plot(dot,tree[first_label][i],self.root)\n",
    "            if isinstance(tree[first_label][i],float):#如果是数字，则生成叶节点\n",
    "                self.root=str(int(self.root)+1)\n",
    "                dot.node(self.root,str(tree[first_label][i]))\n",
    "                dot.edge(inc,self.root,str(i))\n",
    "    #可视化函数\n",
    "    def plot_model(self,tree,name):\n",
    "        dot=Digraph(comment='good')\n",
    "        first_label=list(tree.keys())[0]#找到根节点\n",
    "        dot.node('0',first_label)\n",
    "        self._sub_plot(dot,tree,'0')\n",
    "        return dot   \n",
    "   class ID3(DecisionTree):\n",
    "    def __init__(self,algor='ID3',detla=0.05):\n",
    "        super(ID3,self).__init__()\n",
    "        self.algor=algor\n",
    "        self.detla=detla\n",
    "    def info_gain(self,dataset,i):#计算信息增益\n",
    "        labels=[x[-1] for x in dataset]\n",
    "        entropy,index,candidate_final=self.feaX_entropy(dataset,i)\n",
    "        info_gain=self.cal_entropy(labels)-entropy\n",
    "        return info_gain\n",
    "    def find_max_info_gain(self,dataset):#遍历所有特征下的信息增益，返回最大的信息增益\n",
    "        num_sample=len(dataset[0])-1\n",
    "        find_max=[]\n",
    "        for i in range(num_sample):\n",
    "            find_max.append(self.info_gain(dataset,i))\n",
    "        return find_max.index(max(find_max)),max(find_max)\n",
    "    #构建决策树函数 返回列表\n",
    "    def creatdisiontree(self,dataset,fea_labels,detle):\n",
    "        labels=[x[-1]for x in dataset]#判断标签是否一致，若一致直接返回标签值\n",
    "        if len(list(set(labels)))==1:\n",
    "            return labels[0]\n",
    "        max_entropy_index,max_info_gain=self.find_max_info_gain(dataset)\n",
    "        if max_info_gain<detle:#判断最大信息增益是否小于给定值，若小于则不再生成树\n",
    "            label_count=Counter(labels)\n",
    "            return max(label_count.items(),key=lambda x:x[1])[0]\n",
    "        else:\n",
    "            fea_dic_val={}#用于收集分支的标志和下面的节点\n",
    "            fea_dic={}#用于收集节点和分支\n",
    "            feaX_labels=[[x[max_entropy_index],x[-1]]for x in dataset]\n",
    "            feaX=[x[max_entropy_index] for x in dataset]\n",
    "            fea_labels_new=[]#产生新的特征列表\n",
    "            fea_labels_new.extend(fea_labels[:max_entropy_index]+fea_labels[max_entropy_index+1:])\n",
    "            entropy,index,candidate_final=self.feaX_entropy(dataset,max_entropy_index)\n",
    "            tem_dict={'min_than %s'% (candidate_final):[],'max_than %s'%(candidate_final):[]}\n",
    "            for sample in feaX:#利用最终选取的划分值对样本进行划分\n",
    "                if sample<=candidate_final:\n",
    "                    tem_dict['min_than %s'% (candidate_final)].append(sample)\n",
    "                if sample>candidate_final:\n",
    "                    tem_dict['max_than %s'%(candidate_final)].append(sample)\n",
    "            data_new1=[]\n",
    "            data_new2=[]\n",
    "            for item in dataset:#对样本进行划分，并除去此特征生成新的特征列表\n",
    "                if item[max_entropy_index] in tem_dict['min_than %s'% (candidate_final)]:\n",
    "                    data_new1.append(item[:max_entropy_index]+item[max_entropy_index+1:])\n",
    "                else:\n",
    "                    data_new2.append(item[:max_entropy_index]+item[max_entropy_index+1:])\n",
    "            if len(data_new1)==0:\n",
    "                label1=[y[-1]for y in data_new2]\n",
    "                label1_count=Counter(label1)\n",
    "                return max(label1_count.items(),key=lambda y:y[1])[0]\n",
    "            if len(data_new2)==0:\n",
    "                label2=[y[-1]for y in data_new1]\n",
    "                label2_count=Counter(label2)\n",
    "                return max(label2_count.items(),key=lambda y:y[1])[0]\n",
    "            if len(data_new1)!=0 and len(data_new2)!=0:#如果不是空集，对样本划分，并迭代\n",
    "                fea_dic_val['min_than %s'% (candidate_final)]=fea_dic_val.get('min_than %s'% (candidate_final),self.creatdisiontree(data_new1,fea_labels_new,detle))\n",
    "                fea_dic_val['max_than %s'%(candidate_final)]=fea_dic_val.get('max_than %s'%(candidate_final),self.creatdisiontree(data_new2,fea_labels_new,detle))\n",
    "                #生成节点和分叉\n",
    "                fea_dic[fea_labels[max_entropy_index]]=fea_dic.get(fea_labels[max_entropy_index],fea_dic_val)\n",
    "        return fea_dic\n",
    "class C45(DecisionTree):\n",
    "    def __init__(self,algor='C45',detla=0.05):\n",
    "        super(C45,self).__init__()\n",
    "        self.algor=algor\n",
    "        self.detla=detla\n",
    "    def info_gain_rate(self,dataset,i):#计算信息增益率\n",
    "        labels=[x[-1] for x in dataset]#每次迭代后数据集的标签的熵\n",
    "        entropy,index,candidate_final=self.feaX_entropy(dataset,i)\n",
    "        info_gain=self.cal_entropy(labels)-entropy\n",
    "        feature=[1,0]#因二分法，每次分类的类别数相同，不妨记作1类和0类\n",
    "        entropy_own=self.cal_entropy(feature)\n",
    "        info_gain_rate=info_gain/entropy_own\n",
    "        return info_gain_rate\n",
    "    def find_max_info_gain_rate(self,dataset):#遍历所有特征下的信息增益率，返回最大的信息增益率\n",
    "        num_sample=len(dataset[1])-1\n",
    "        find_max=[]\n",
    "        for i in range(num_sample):\n",
    "            find_max.append(self.info_gain_rate(dataset,i))\n",
    "        return find_max.index(max(find_max)),max(find_max)\n",
    "    def creatdisiontree(self,dataset,fea_labels,detle):\n",
    "        labels=[x[-1]for x in dataset]\n",
    "        if len(list(set(labels)))==1:#判断标签是否一致，若一致直接返回标签值\n",
    "            return labels[0]\n",
    "        max_entropy_index,max_info_gain_rate=self.find_max_info_gain_rate(dataset)\n",
    "        if max_info_gain_rate<detle:#判断最大信息增益率是否小于给定值，若小于则不再生成树\n",
    "            label_count=Counter(labels)\n",
    "            return max(label_count.items(),key=lambda x:x[1])[0]\n",
    "        else:\n",
    "            fea_dic_val={}#用于收集分支的标志和下面的节点\n",
    "            fea_dic={}\n",
    "            feaX_labels=[[x[max_entropy_index],x[-1]]for x in dataset]#提取数据\n",
    "            feaX=[x[max_entropy_index] for x in dataset]#提取数据\n",
    "            def takefirst(elem):\n",
    "                return elem[0]\n",
    "            feaX_labels.sort(key=takefirst)\n",
    "            feaX.sort()\n",
    "            fea_labels_new=[]#产生新的特征列表\n",
    "            fea_labels_new.extend(fea_labels[:max_entropy_index]+fea_labels[max_entropy_index+1:])\n",
    "            entropy,index,candidate_final=self.feaX_entropy(dataset,max_entropy_index)\n",
    "            tem_dict={'min_than %s'% (candidate_final):[],'max_than %s'%(candidate_final):[]}\n",
    "            for sample in feaX:\n",
    "                if sample<=candidate_final:\n",
    "                    tem_dict['min_than %s'% (candidate_final)].append(sample)\n",
    "                else:\n",
    "                    tem_dict['max_than %s'%(candidate_final)].append(sample)\n",
    "            data_new1=[]\n",
    "            data_new2=[]\n",
    "            for item in dataset:#对样本进行划分，并除去此特征生成新的特征列表\n",
    "                    if item[max_entropy_index] in tem_dict['min_than %s'% (candidate_final)]:\n",
    "                        data_new1.append(item[:max_entropy_index]+item[max_entropy_index+1:])\n",
    "                    else:\n",
    "                        data_new2.append(item[:max_entropy_index]+item[max_entropy_index+1:])\n",
    "            if len(data_new1)==0:#判断划分的新数据集是否是空集，如是空集，直接返回另一个数据集标签最多项\n",
    "                label1=[y[-1]for y in data_new2]\n",
    "                label1_count=Counter(label1)\n",
    "                return max(label1_count.items(),key=lambda y:y[1])[0]\n",
    "            if len(data_new2)==0:\n",
    "                label2=[y[-1]for y in data_new1]\n",
    "                label2_count=Counter(label2)\n",
    "                return max(label2_count.items(),key=lambda y:y[1])[0]\n",
    "            if len(data_new1)!=0 and len(data_new2)!=0:#如果不是空集，对样本划分，并迭代\n",
    "                fea_dic_val['min_than %s'% (candidate_final)]=fea_dic_val.get('min_than %s'% (candidate_final),self.creatdisiontree(data_new1,fea_labels_new,detle))\n",
    "                fea_dic_val['max_than %s'%(candidate_final)]=fea_dic_val.get('max_than %s'%(candidate_final),self.creatdisiontree(data_new2,fea_labels_new,detle))\n",
    "                #生成节点和分叉\n",
    "                fea_dic[fea_labels[max_entropy_index]]=fea_dic.get(fea_labels[max_entropy_index],fea_dic_val)\n",
    "        return fea_dic\n",
    "class CART(DecisionTree):\n",
    "    def __init__(self,algor='CART',detla=0.0706):\n",
    "        super(CART,self).__init__()\n",
    "        self.algor=algor\n",
    "        self.detla=detla\n",
    "    def cal_gini(self,labels):\n",
    "        gini=0.0\n",
    "        dic_1={}#统计每个标签出现的次数\n",
    "        for item in labels:#计算gini系数\n",
    "            dic_1[item]=dic_1.get(item,0)+1\n",
    "        for itemN in dic_1:\n",
    "            prod=dic_1[itemN]/len(labels)\n",
    "            gini+=prod*(1-prod)\n",
    "        return gini\n",
    "    def feaX_gini(self,dataset,i):\n",
    "        gini=0.0\n",
    "        feaX_labels=[[x[i],x[-1]] for x in dataset]\n",
    "        feaX=[x[i] for x in dataset]\n",
    "        def takefirst(elem):\n",
    "            return elem[0]\n",
    "        feaX_labels.sort(key=takefirst)\n",
    "        feaX.sort()\n",
    "        candidate=[]\n",
    "        labels=[]\n",
    "        labels1=[]\n",
    "        gini_list=[]\n",
    "        for i in range(len(feaX)-1):#求出所有的可能划分值\n",
    "            candidate.append((feaX[i]+feaX[i+1])/2)\n",
    "        #遍历所有的可能划分值，并求出最小gini系数下的划分值，gini系数，索引\n",
    "        for candidate_sample in candidate:\n",
    "            count=0\n",
    "            for feaX_labels_sample in feaX_labels:\n",
    "                if candidate_sample<=feaX_labels_sample[0] :\n",
    "                    count+=1\n",
    "                    labels.append(feaX_labels_sample[-1])\n",
    "                else:\n",
    "                    labels1.append(feaX_labels_sample[-1])\n",
    "            gini=count/len(feaX)*self.cal_gini(labels)+(len(feaX)-count)/len(feaX)*self.cal_gini(labels1)\n",
    "            gini_list.append(gini)\n",
    "        return min(gini_list),gini_list.index(min(gini_list)),candidate[gini_list.index(min(gini_list))]\n",
    "    def gini_down(self,dataset,i):#计算给定的特征下的gini系数与样本数据集的差值\n",
    "        labels=[x[-1] for x in dataset]\n",
    "        gini,index,candidate_final=self.feaX_gini(dataset,i)\n",
    "        gini_down=self.cal_gini(labels)-gini\n",
    "        return gini_down\n",
    "    def find_max_gini_down(self,dataset):#遍历所有特征找到最佳划分值\n",
    "        num_sample=len(dataset[1])-1\n",
    "        find_max=[]\n",
    "        for i in range(num_sample):\n",
    "            find_max.append(self.gini_down(dataset,i))\n",
    "        return find_max.index(max(find_max)),max(find_max)\n",
    "    def creatdisiontree(self,dataset,fea_labels,detle):\n",
    "        labels=[x[-1]for x in dataset]#判断迭代后的标签种类，若相同，则返回标签值\n",
    "        if len(list(set(labels)))==1:\n",
    "            return labels[0]\n",
    "        max_gini_down_index,max_gini_down=self.find_max_gini_down(dataset)\n",
    "        if max_gini_down<detle:#判断最大的下降值与给定值的比较，若小于，则停止迭代\n",
    "            label_count=Counter(labels)\n",
    "            return max(label_count.items(),key=lambda x:x[1])[0]\n",
    "        else:\n",
    "            fea_dic_val={}\n",
    "            fea_dic={}\n",
    "            feaX_labels=[[x[max_gini_down_index],x[-1]]for x in dataset]\n",
    "            feaX=[x[max_gini_down_index] for x in dataset]\n",
    "            def takefirst(elem):\n",
    "                return elem[0]\n",
    "            feaX_labels.sort(key=takefirst)\n",
    "            feaX.sort()\n",
    "            fea_labels_new=[]\n",
    "            fea_labels_new.extend(fea_labels[:max_gini_down_index]+fea_labels[max_gini_down_index+1:])\n",
    "            gini,index,candidate_final=self.feaX_gini(dataset,max_gini_down_index)\n",
    "            tem_dict={'min_than %s'% (candidate_final):[],'max_than %s'%(candidate_final):[]}\n",
    "            for sample in feaX:\n",
    "                if sample<=candidate_final:\n",
    "                    tem_dict['min_than %s'% (candidate_final)].append(sample)\n",
    "                else:\n",
    "                    tem_dict['max_than %s'%(candidate_final)].append(sample)\n",
    "            data_new1=[]\n",
    "            data_new2=[]\n",
    "            for item in dataset:#对样本进行划分，并除去此特征生成新的特征列表\n",
    "                if item[ max_gini_down_index] in tem_dict['min_than %s'% (candidate_final)]:\n",
    "                    data_new1.append(item[: max_gini_down_index]+item[ max_gini_down_index+1:])\n",
    "                else:\n",
    "                    data_new2.append(item[: max_gini_down_index]+item[ max_gini_down_index+1:])\n",
    "            if len(data_new1)==0:\n",
    "                label1=[y[-1]for y in data_new2]\n",
    "                label1_count=Counter(label1)\n",
    "                return max(label1_count.items(),key=lambda y:y[1])[0]\n",
    "            if len(data_new2)==0:\n",
    "                label2=[y[-1]for y in data_new1]\n",
    "                label2_count=Counter(label2)\n",
    "                return max(label2_count.items(),key=lambda y:y[1])[0]\n",
    "            if len(data_new1)!=0 and len(data_new2)!=0:#如果不是空集，对样本划分，并迭代\n",
    "                fea_dic_val['min_than %s'% (candidate_final)]=fea_dic_val.get('min_than %s'% (candidate_final),self.creatdisiontree(data_new1,fea_labels_new,detle))\n",
    "                fea_dic_val['max_than %s'%(candidate_final)]=fea_dic_val.get('max_than %s'%(candidate_final),self.creatdisiontree(data_new2,fea_labels_new,detle))\n",
    "                #生成节点和分叉\n",
    "                fea_dic[fea_labels[max_entropy_index]]=fea_dic.get(fea_labels[max_entropy_index],fea_dic_val)\n",
    "        return fea_dic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
