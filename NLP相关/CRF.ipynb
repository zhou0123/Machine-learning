{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./词性标注.txt',encoding='UTF-8') as f:\n",
    "    data=f.readlines()[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data[i]=data[i][24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words_labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    if len(data[i])==0:\n",
    "        continue\n",
    "    list1=data[i][0:-1].split(\"  \")\n",
    "    data_words_labels=data_words_labels+list1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words_labels2=list(set(data_words_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Words=[]\n",
    "data_label=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_words_labels2)):\n",
    "    list2=data_words_labels2[i].split(\"/\")\n",
    "    data_Words.append(list2[0])\n",
    "    data_label.append(list2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_data_label=list(set(data_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_words=len(set(data_Words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_data_words=list(set(data_Words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_word_onehot=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_of_words):\n",
    "    vec=np.zeros(num_of_words)\n",
    "    vec[i]=1\n",
    "    list_of_word_onehot.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_labels_onehot=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(samp_data_label)):\n",
    "    list_of_labels_onehot.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels_to_onehot=dict(zip(samp_data_label,list_of_labels_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_word_to_onehot=dict(zip(set_data_words,list_of_word_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data[i]=data[i][0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    ran_list.append(random.randint(0,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_list=list(set(ran_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_train=[]\n",
    "data_for_test=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    if i in ran_list:\n",
    "        data_for_test.append(data[i])\n",
    "    else:\n",
    "        data_for_train.append(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_matrix(sentence):\n",
    "    sentence=sentence[0:-1]\n",
    "    list_words=sentence.split(\"  \")\n",
    "    list_new=list_words[0].split(\"/\")\n",
    "    matrix_for_words=dict_word_to_onehot[list_new[0]].reshape(1,8132)\n",
    "    matrix_for_labels=[dict_labels_to_onehot[list_new[-1].strip()]]\n",
    "    for i in range(1,len(list_words)):\n",
    "        list_new=list_words[i].split(\"/\")\n",
    "        \n",
    "        matrix_for_words=np.vstack((matrix_for_words,dict_word_to_onehot[list_new[0]].reshape(1,8132)))\n",
    "        matrix_for_labels=matrix_for_labels+[dict_labels_to_onehot[list_new[-1].strip()]]\n",
    "    return matrix_for_words,matrix_for_labels\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_for_train=[]\n",
    "mat_for_test=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=0\n",
    "for i in data_for_train:\n",
    " \n",
    "    if len(i)==0:\n",
    "        continue\n",
    "    \n",
    "    words,labels=sentence_to_matrix(i)\n",
    "    mat_for_train.append((words,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_for_test:\n",
    "    if len(i)==0:\n",
    "        continue\n",
    "    \n",
    "    words,labels=sentence_to_matrix(i)\n",
    "    mat_for_test.append((words,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4191, 0.1748, 0.8702,  ..., 0.8389, 0.5127, 0.6536],\n",
       "        [0.2969, 0.4465, 0.3958,  ..., 0.7848, 0.5995, 0.1338],\n",
       "        [0.5605, 0.8033, 0.2301,  ..., 0.2197, 0.3952, 0.0488],\n",
       "        ...,\n",
       "        [0.6744, 0.6846, 0.2045,  ..., 0.2560, 0.8135, 0.2139],\n",
       "        [0.8684, 0.4770, 0.1912,  ..., 0.7969, 0.9659, 0.6693],\n",
       "        [0.3365, 0.2814, 0.4803,  ..., 0.8751, 0.6480, 0.1884]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=Variable(torch.rand(8132,47,dtype=torch.float64),requires_grad=True)\n",
    "w2=Variable(torch.rand(47,47,dtype=torch.float64),requires_grad=True)\n",
    "learning_rate=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRF(n,input_dataset,labels):\n",
    "    input_dataset=torch.from_numpy(input_dataset)\n",
    "    input_dataset=Variable(input_dataset,requires_grad=False)\n",
    "    Z=(input_dataset[0].reshape(1,8132)).mm(w1)\n",
    "    sum_exp=Z[0,labels[0]]\n",
    "    for i in range(n-1):\n",
    "        x=torch.zeros(1,47,dtype=float)\n",
    "        x[0,np.argmax(labels[i+1])]=1\n",
    "        score1=x.mm(w2)[0,labels[i+1]]\n",
    "        score2=(input_dataset[i+1].reshape(1,8132)).mm(w1)[0,labels[i+1]]\n",
    "        sum_exp=sum_exp+score1+score2\n",
    "    up_score=sum_exp\n",
    "    \n",
    "    \n",
    "    for i in range(n-1):\n",
    "        x=torch.zeros(1,47,dtype=float)\n",
    "        x[0,np.argmax(labels[i+1])]=1\n",
    "        score1=x.mm(w2)\n",
    "        score2=(input_dataset[i+1].reshape(1,8132)).mm(w1)\n",
    "        Z=Z+score1+score2\n",
    "    all_Z=torch.sum(Z)\n",
    "    \n",
    "    p=-up_score/all_Z\n",
    "    \n",
    "\n",
    "    loss=p\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    w1.data-=learning_rate*w1.grad.data\n",
    "    w2.data-=learning_rate*w2.grad.data\n",
    "        \n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs,all_data):\n",
    "    for i in range(epochs):\n",
    "        #print(w1)\n",
    "        num=0\n",
    "        print(\"\\r总进度完成%.2f %%\" % (i *100 /epochs), end=\"\")\n",
    "        print()\n",
    "        for input_dataset,labels in all_data:\n",
    "            num+=1\n",
    "            print(\"\\r子进度完成%.2f %%\" % (num *100 /len(all_data)), end=\"\")\n",
    "\n",
    "            \n",
    "            CRF(len(input_dataset),input_dataset,labels)\n",
    "        print()\n",
    "\n",
    "    return w1,w2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " [22, 22, 45, 44, 46, 45, 43, 38, 38, 45, 43, 22, 45, 35, 24, 43])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_for_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总进度完成0.00 %\n",
      "子进度完成100.00 %\n",
      "总进度完成10.00 %\n",
      "子进度完成100.00 %\n",
      "总进度完成20.00 %\n",
      "子进度完成100.00 %\n",
      "总进度完成30.00 %\n",
      "子进度完成100.00 %\n",
      "总进度完成40.00 %\n",
      "子进度完成100.00 %\n",
      "总进度完成50.00 %\n",
      "子进度完成100.00 %\n",
      "总进度完成60.00 %\n",
      "子进度完成100.00 %\n",
      "总进度完成70.00 %\n",
      "子进度完成100.00 %\n",
      "总进度完成80.00 %\n",
      "子进度完成100.00 %\n",
      "总进度完成90.00 %\n",
      "子进度完成100.00 %\n"
     ]
    }
   ],
   "source": [
    "w1,w2=train(10,mat_for_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best(input_dataset,n,true_labels):\n",
    "    input_dataset=torch.from_numpy(input_dataset)\n",
    "\n",
    "    input_dataset=Variable(input_dataset,requires_grad=False)\n",
    "    list_Z=[]\n",
    "    \n",
    "    G=w2\n",
    "    Z=(input_dataset[0].reshape(1,8132)).mm(w1)\n",
    "    list_Z.append(Z)\n",
    "    for i in range(n-1):\n",
    "        Z=(Z.mm(G)).mul(((input_dataset[i+1].reshape(1,8132)).mm(w1)))\n",
    "        list_Z.append(Z)\n",
    "    \n",
    "    \n",
    "    list_label=[]\n",
    "    \n",
    "    for i in range(len(list_Z)):\n",
    "        list_label.append(true_labels[list(list_Z[i].detach().numpy()[0]).index(max(list(list_Z[i].detach().numpy()[0])))])\n",
    "    return list_label\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(input_dataset,samp_data_label):\n",
    "    list_label=find_best(input_dataset[0],len(input_dataset[0]),samp_data_label)\n",
    "    num1=0\n",
    "    #num1=sum(np.array(input_dataset[1])==np.array(list_label))\n",
    "    num2=len(input_dataset[1])\n",
    "    for i in range(len(list_label)):\n",
    "        if list_label[i]==samp_data_label[input_dataset[1][i]]:\n",
    "            num1+=1\n",
    "        \n",
    "    \n",
    "    return num1,num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04043351396415173\n"
     ]
    }
   ],
   "source": [
    "sum1=0\n",
    "sum2=0\n",
    "for i in mat_for_test:\n",
    "    num1,num2=test(i,samp_data_label)\n",
    "    sum1+=num1\n",
    "    sum2+=num2\n",
    "print(sum1/sum2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
