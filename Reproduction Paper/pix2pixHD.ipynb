{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import scipy.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import zipfile\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(image_file):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "\n",
    "    w = tf.shape(image)[1]\n",
    "\n",
    "    w = w // 2\n",
    "    real_image = image[:, :w, :]\n",
    "    input_image = image[:, w:, :]\n",
    "\n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    real_image = tf.cast(real_image, tf.float32)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.loadmat(directory_name + \"/\" + filename)\n",
    "        array_of_img.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import scipy.io as scio\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataFile = r'/folder／reggae.00041.mat' # 单个的mat文件\n",
    "data = scio.loadmat(dataFile)\n",
    "print(type(data))\n",
    "# print (data['data']) \n",
    "# 由于导入的mat文件是structure类型的，所以需要取出需要的数据矩阵\n",
    "a=data['data']\n",
    "# 取出需要的数据矩阵\n",
    "\n",
    "# 数据矩阵转图片的函数\n",
    "def MatrixToImage(data):\n",
    "    data = data*255\n",
    "    new_im = Image.fromarray(data.astype(np.uint8))\n",
    "    return new_im\n",
    "\n",
    "new_im = MatrixToImage(a)\n",
    "plt.imshow(a, cmap=plt.cm.gray, interpolation='nearest')\n",
    "new_im.show()\n",
    "new_im.save('reggae.00041.bmp') # 保存图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load (input_image_file,real_image_file):\n",
    "    \n",
    "    \n",
    "    real_image=tf.io.real_file(real_image_file)\n",
    "    real_image=tf.image.decode_jpeg(real_image)\n",
    "    \n",
    "    input_image=tf.cast(input_image,tf.float32)\n",
    "    real_image=tf.cast(real_image,tf.float32)\n",
    "    \n",
    "    return input_image,real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(filters,size):\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    block=tf.keras.Sequential()\n",
    "    block.add(tf.keras.layers.ZeroPadding2D(1))\n",
    "    block.add(tf.keras.layers.Conv2D(filters,size,strides=1,padding='valid',kernel_initializer=initializer,use_bias=False))\n",
    "    block.add(tf.keras.layers.BatchNormalization())\n",
    "    block.add(tf.keras.layers.ReLU())\n",
    "    block.add(tf.keras.layers.ZeroPadding2D(1))\n",
    "    block.add(tf.keras.layers.Conv2D(filters,size,strides=1,padding='valid',kernel_initializer=initializer,use_bias=False))\n",
    "    block.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample(filters,size):\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    block=tf.keras.Sequential()\n",
    "    block.add(tf.keras.layers.Conv2D(filters,size,strides=2,padding='same',kernel_initializer=initializer,use_bias=False))\n",
    "    block.add(tf.keras.layers.BatchNormalization())\n",
    "    block.add(tf.keras.layers.ReLU())\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_sample(filters,size):\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    block=tf.keras.Sequential()\n",
    "    block.add(tf.keras.layers.Conv2DTranspose(filters,size,strides=2,padding='same',kernel_initializer=initializer,use_bias=False))\n",
    "    block.add(tf.keras.layers.BatchNormalization())\n",
    "    block.add(tf.keras.layers.ReLU())\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    inputs=tf.keras.layers.Input(shape=[512,512,3])#标签\n",
    "    \n",
    "    \n",
    "    \n",
    "    #outputs_mean=encoder(x3,inputs)\n",
    "    \n",
    "    #local\n",
    "    x2=inputs\n",
    "    x2=tf.keras.layers.ZeroPadding2D(3)(x2)\n",
    "    x2=tf.keras.layers.Conv2D(64,7,strides=1,padding='valid',kernel_initializer=initializer,use_bias=False)(x2)\n",
    "    x2=tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2=tf.keras.layers.ReLU()(x2)\n",
    "    \n",
    "    x2=tf.keras.layers.Conv2D(64,3,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x2)\n",
    "    x2=tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2=tf.keras.layers.ReLU()(x2)#(256,256,64)\n",
    "    \n",
    "    \n",
    "    residual_blocks=[\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3),\n",
    "        residual_block(512,3)\n",
    "    ]\n",
    "    residual_blocks2=[\n",
    "        residual_block(256,3),\n",
    "        residual_block(256,3),\n",
    "        residual_block(256,3),\n",
    "        residual_block(256,3),\n",
    "        residual_block(256,3),\n",
    "        residual_block(256,3),\n",
    "        residual_block(256,3),\n",
    "        residual_block(256,3),\n",
    "        residual_block(256,3)\n",
    "    ]\n",
    "    #global\n",
    "    x1=tf.image.resize(inputs,(256,256))\n",
    "    x1=tf.keras.layers.ZeroPadding2D(3)(x1)\n",
    "    x1=tf.keras.layers.Conv2D(64,7,strides=1,padding='valid',kernel_initializer=initializer,use_bias=False)(x1)\n",
    "    x1=tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1=tf.keras.layers.ReLU()(x1)\n",
    "    \n",
    "    #下采样 此时输入为（256，256，64）\n",
    "    x1=tf.keras.layers.Conv2D(128,3,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x1)#(128,128,128)\n",
    "    x1=tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1=tf.keras.layers.ReLU()(x1)\n",
    "    x1=tf.keras.layers.Conv2D(256,3,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x1)#(64,64,256)\n",
    "    x1=tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1=tf.keras.layers.ReLU()(x1)\n",
    "    x1=tf.keras.layers.Conv2D(512,3,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x1)#(32,32,512)\n",
    "    x1=tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1=tf.keras.layers.ReLU()(x1)\n",
    "    \n",
    "    #残差\n",
    "    for block in residual_blocks:\n",
    "        x11=block(x1)\n",
    "        x1=tf.add(x1,x11)\n",
    "    #上采样此时（32，32，512）\n",
    "    x1=tf.keras.layers.Conv2DTranspose(256,3,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x1)#(64,64,256)\n",
    "    x1=tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1=tf.keras.layers.ReLU()(x1)\n",
    "    x1=tf.keras.layers.Conv2DTranspose(128,3,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x1)#(128,128,128)\n",
    "    x1=tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1=tf.keras.layers.ReLU()(x1)\n",
    "    x1=tf.keras.layers.Conv2DTranspose(64,3,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x1)#(256,256,64)\n",
    "    x1=tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1=tf.keras.layers.ReLU()(x1)\n",
    "    x12=x1\n",
    "    \n",
    "    x1=tf.keras.layers.Conv2D(3,7,strides=1,padding='same',kernel_initializer=initializer,use_bias=False,activation='tanh')(x1)\n",
    "    \n",
    "    x2=tf.add(x12,x2)#(256,256,64)\n",
    "    \n",
    "    x2=tf.keras.layers.Conv2D(128,3,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(x2)\n",
    "    x2=tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2=tf.keras.layers.ReLU()(x2)\n",
    "    x2=tf.keras.layers.Conv2D(256,3,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(x2)\n",
    "    x2=tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2=tf.keras.layers.ReLU()(x2)\n",
    "    \n",
    "    for block in residual_blocks2:\n",
    "        x22=block(x2)\n",
    "        x2=tf.add(x2,x22)\n",
    "    #(256,256,256)\n",
    "    x2=tf.keras.layers.Conv2D(128,3,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(x2)\n",
    "    x2=tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2=tf.keras.layers.ReLU()(x2)#(256,256,128)\n",
    "    x2=tf.keras.layers.Conv2D(64,3,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(x2)\n",
    "    x2=tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2=tf.keras.layers.ReLU()(x2)#(256,256,64)\n",
    "    x2=tf.keras.layers.Conv2DTranspose(64,3,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x2)\n",
    "    x2=tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2=tf.keras.layers.ReLU()(x2)#(512,512,64)\n",
    "    \n",
    "    x2=tf.keras.layers.Conv2D(3,7,strides=1,padding='same',kernel_initializer=initializer,use_bias=False,activation='tanh')(x2)\n",
    "    \n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs,outputs=x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_38\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_37 (InputLayer)           [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ResizeBilinear_1 (T [(None, 256, 256, 3) 0           input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_83 (ZeroPadding2 (None, 262, 262, 3)  0           tf_op_layer_ResizeBilinear_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 256, 256, 64) 9408        zero_padding2d_83[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 256, 256, 64) 256         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_88 (ReLU)                 (None, 256, 256, 64) 0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 128, 128, 128 73728       re_lu_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 128, 128, 128 512         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_89 (ReLU)                 (None, 128, 128, 128 0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 64, 64, 256)  294912      re_lu_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 64, 64, 256)  1024        conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_90 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 32, 32, 512)  1179648     re_lu_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 32, 32, 512)  2048        conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_91 (ReLU)                 (None, 32, 32, 512)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_73 (Sequential)      (None, 32, 32, 512)  4722688     re_lu_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_19 (TensorFlowO [(None, 32, 32, 512) 0           re_lu_91[0][0]                   \n",
      "                                                                 sequential_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_74 (Sequential)      (None, 32, 32, 512)  4722688     tf_op_layer_Add_19[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_20 (TensorFlowO [(None, 32, 32, 512) 0           tf_op_layer_Add_19[0][0]         \n",
      "                                                                 sequential_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_75 (Sequential)      (None, 32, 32, 512)  4722688     tf_op_layer_Add_20[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_21 (TensorFlowO [(None, 32, 32, 512) 0           tf_op_layer_Add_20[0][0]         \n",
      "                                                                 sequential_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_76 (Sequential)      (None, 32, 32, 512)  4722688     tf_op_layer_Add_21[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_22 (TensorFlowO [(None, 32, 32, 512) 0           tf_op_layer_Add_21[0][0]         \n",
      "                                                                 sequential_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_77 (Sequential)      (None, 32, 32, 512)  4722688     tf_op_layer_Add_22[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_23 (TensorFlowO [(None, 32, 32, 512) 0           tf_op_layer_Add_22[0][0]         \n",
      "                                                                 sequential_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_78 (Sequential)      (None, 32, 32, 512)  4722688     tf_op_layer_Add_23[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_24 (TensorFlowO [(None, 32, 32, 512) 0           tf_op_layer_Add_23[0][0]         \n",
      "                                                                 sequential_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_79 (Sequential)      (None, 32, 32, 512)  4722688     tf_op_layer_Add_24[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_25 (TensorFlowO [(None, 32, 32, 512) 0           tf_op_layer_Add_24[0][0]         \n",
      "                                                                 sequential_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_80 (Sequential)      (None, 32, 32, 512)  4722688     tf_op_layer_Add_25[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_26 (TensorFlowO [(None, 32, 32, 512) 0           tf_op_layer_Add_25[0][0]         \n",
      "                                                                 sequential_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_81 (Sequential)      (None, 32, 32, 512)  4722688     tf_op_layer_Add_26[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_27 (TensorFlowO [(None, 32, 32, 512) 0           tf_op_layer_Add_26[0][0]         \n",
      "                                                                 sequential_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_20 (Conv2DTran (None, 64, 64, 256)  1179648     tf_op_layer_Add_27[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 64, 64, 256)  1024        conv2d_transpose_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_92 (ReLU)                 (None, 64, 64, 256)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_46 (ZeroPadding2 (None, 518, 518, 3)  0           input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DTran (None, 128, 128, 128 294912      re_lu_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 512, 512, 64) 9408        zero_padding2d_46[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 128, 128, 128 512         conv2d_transpose_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 512, 512, 64) 256         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_93 (ReLU)                 (None, 128, 128, 128 0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_68 (ReLU)                 (None, 512, 512, 64) 0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DTran (None, 256, 256, 64) 73728       re_lu_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 256, 256, 64) 36864       re_lu_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 256, 256, 64) 256         conv2d_transpose_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 256, 256, 64) 256         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_94 (ReLU)                 (None, 256, 256, 64) 0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_69 (ReLU)                 (None, 256, 256, 64) 0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_28 (TensorFlowO [(None, 256, 256, 64 0           re_lu_94[0][0]                   \n",
      "                                                                 re_lu_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 256, 256, 128 73728       tf_op_layer_Add_28[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 256, 256, 128 512         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_95 (ReLU)                 (None, 256, 256, 128 0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 256, 256, 256 294912      re_lu_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 256, 256, 256 1024        conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_96 (ReLU)                 (None, 256, 256, 256 0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_82 (Sequential)      (None, 256, 256, 256 1181696     re_lu_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_29 (TensorFlowO [(None, 256, 256, 25 0           re_lu_96[0][0]                   \n",
      "                                                                 sequential_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_83 (Sequential)      (None, 256, 256, 256 1181696     tf_op_layer_Add_29[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_30 (TensorFlowO [(None, 256, 256, 25 0           tf_op_layer_Add_29[0][0]         \n",
      "                                                                 sequential_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_84 (Sequential)      (None, 256, 256, 256 1181696     tf_op_layer_Add_30[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_31 (TensorFlowO [(None, 256, 256, 25 0           tf_op_layer_Add_30[0][0]         \n",
      "                                                                 sequential_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_85 (Sequential)      (None, 256, 256, 256 1181696     tf_op_layer_Add_31[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_32 (TensorFlowO [(None, 256, 256, 25 0           tf_op_layer_Add_31[0][0]         \n",
      "                                                                 sequential_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_86 (Sequential)      (None, 256, 256, 256 1181696     tf_op_layer_Add_32[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_33 (TensorFlowO [(None, 256, 256, 25 0           tf_op_layer_Add_32[0][0]         \n",
      "                                                                 sequential_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_87 (Sequential)      (None, 256, 256, 256 1181696     tf_op_layer_Add_33[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_34 (TensorFlowO [(None, 256, 256, 25 0           tf_op_layer_Add_33[0][0]         \n",
      "                                                                 sequential_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_88 (Sequential)      (None, 256, 256, 256 1181696     tf_op_layer_Add_34[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_35 (TensorFlowO [(None, 256, 256, 25 0           tf_op_layer_Add_34[0][0]         \n",
      "                                                                 sequential_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_89 (Sequential)      (None, 256, 256, 256 1181696     tf_op_layer_Add_35[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_36 (TensorFlowO [(None, 256, 256, 25 0           tf_op_layer_Add_35[0][0]         \n",
      "                                                                 sequential_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_90 (Sequential)      (None, 256, 256, 256 1181696     tf_op_layer_Add_36[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_37 (TensorFlowO [(None, 256, 256, 25 0           tf_op_layer_Add_36[0][0]         \n",
      "                                                                 sequential_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 256, 256, 128 294912      tf_op_layer_Add_37[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 256, 256, 128 512         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_97 (ReLU)                 (None, 256, 256, 128 0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 256, 256, 64) 73728       re_lu_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 256, 256, 64) 256         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_98 (ReLU)                 (None, 256, 256, 64) 0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DTran (None, 512, 512, 64) 36864       re_lu_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 512, 512, 64) 256         conv2d_transpose_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_99 (ReLU)                 (None, 512, 512, 64) 0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 512, 512, 3)  9408        re_lu_99[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 57,083,968\n",
      "Trainable params: 57,051,968\n",
      "Non-trainable params: 32,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Generator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sam(filters,size,strides=2):\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    block=tf.keras.Sequential()\n",
    "    \n",
    "    block.add(tf.keras.layers.Conv2D(filters,size,strides=strides,padding='same',kernel_initializer=initializer,use_bias=False))\n",
    "    block.add(tf.keras.layers.BatchNormalization())\n",
    "    block.add(tf.keras.layers.LeakyReLU())\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_Discriminator():\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    inputs=tf.keras.layers.Input(shape=[256,256,3])\n",
    "    \n",
    "    x=inputs\n",
    "    downs=[\n",
    "        down_sam(128,4),\n",
    "        down_sam(256,4),\n",
    "        down_sam(512,4,strides=1)\n",
    "    ]\n",
    "    \n",
    "    x=tf.keras.layers.Conv2D(64,4,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x)\n",
    "    x=tf.keras.layers.LeakyReLU()(x)#(256,256,64)\n",
    "    \n",
    "    for down in downs:\n",
    "        x=down(x)\n",
    "    #(32,32,512)\n",
    "    x=tf.keras.layers.Conv2D(64,4,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(x)\n",
    "    x=tf.keras.layers.BatchNormalization()(x)\n",
    "    x=tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    x=tf.keras.layers.Conv2D(1,4,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs,outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_Discriminator():\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    inputs=tf.keras.layers.Input(shape=[512,512,3])\n",
    "    \n",
    "    x=inputs\n",
    "    downs=[\n",
    "        down_sam(128,4),\n",
    "        down_sam(256,4),\n",
    "        down_sam(512,4)\n",
    "    ]\n",
    "    \n",
    "    x=tf.keras.layers.Conv2D(64,4,strides=2,padding='same',kernel_initializer=initializer,use_bias=False)(x)\n",
    "    x=tf.keras.layers.LeakyReLU()(x)#(256,256,64)\n",
    "    \n",
    "    for down in downs:\n",
    "        x=down(x)\n",
    "    #(32,32,512)\n",
    "    x=tf.keras.layers.Conv2D(64,4,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(x)\n",
    "    x=tf.keras.layers.BatchNormalization()(x)\n",
    "    x=tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    x=tf.keras.layers.Conv2D(1,4,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs,outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiscaleDiscriminator():\n",
    "    inputs=tf.keras.layers.Input([512,512,3])\n",
    "    x=inputs\n",
    "    \n",
    "    x1=tf.keras.layers.AveragePooling2D(3,strides=2,padding='same')(x)\n",
    "    \n",
    "    output1=L_Discriminator()(x)\n",
    "    output2=S_Discriminator()(x1)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs,outputs=[output1,output2])#大，小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg19():\n",
    "    inputs=tf.keras.layers.Input([512,512,3])\n",
    "    x=inputs\n",
    "    model=tf.keras.applications.VGG19(input_shape=(512,512,3),weights='imagenet',include_top=False)\n",
    "    slice1=tf.keras.Sequential()\n",
    "    slice2=tf.keras.Sequential()\n",
    "    slice3=tf.keras.Sequential()\n",
    "    slice4=tf.keras.Sequential()\n",
    "    slice5=tf.keras.Sequential()\n",
    "    \n",
    "    for i in range(4):\n",
    "        slice1.add(model.layers[i])\n",
    "    for i in range(4,7):\n",
    "        slice2.add(model.layers[i])\n",
    "    for i in range(7,12):\n",
    "        slice3.add(model.layers[i])\n",
    "    for i in range(12,17):\n",
    "        slice4.add(model.layers[i])\n",
    "    for i in range(17,22):\n",
    "        slice5.add(model.layers[i])\n",
    "    \n",
    "    x1=slice1(x)\n",
    "    x2=slice2(x1)\n",
    "    x3=slice3(x2)\n",
    "    x4=slice4(x3)\n",
    "    x5=slice5(x4)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs,outputs=[x1,x2,x3,x4,x5])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 100\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator_loss(target,gen_dis_image_L,gen_dis_image_S,gen_image):#gen_image:(512,512,3) \n",
    "    gan_loss=loss_object(tf.ones_like(gen_dis_image_L),gen_dis_image_L)+loss_object(tf.ones_like(gen_dis_image_S),gen_dis_image_S)\n",
    "    \n",
    "    weight=[1/32,1/16,1/8,1/4,1]\n",
    "    x1,x2,x3,x4,x5=vgg19(gen_image)\n",
    "    x_1=[x1,x2,x3,x4,x5]\n",
    "    x11,x22,x33,x44,x55=vgg19(target)\n",
    "    x_11=[x11,x22,x33,x44,x55]\n",
    "    l1_loss=0\n",
    "    for i in range(5):\n",
    "        l1_loss+=weight[i]*tf.reduce_mean(tf.abs(x1[i]-x_11[i]))\n",
    "    total_gen_loss=gan_loss+LAMBDA*l1_loss\n",
    "    \n",
    "    return total_gen_loss,gan_loss,l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiscaleDiscriminator_loss(L_target,S_target,L_gen_image,S_gen_image):\n",
    "    real_loss=loss_object(tf.ones_like(L_target),L_target)+loss_object(tf.ones_like(S_target),S_target)\n",
    "    \n",
    "    generated_loss=loss_object(tf.zeros_like(L_gen_image),L_gen_image)+loss_object(tf.zeros_like(S_gen_image),S_gen_image)\n",
    "    \n",
    "    total_Dis_loss=real_loss+generated_loss\n",
    "    return total_Dis_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(input_image,target,epoch):\n",
    "    with tf.GradientTape() as gen_tape,tf.GradientTape() as disc_tape:\n",
    "        gen_image=Generator(input_image,training=True)\n",
    "        \n",
    "        gen_dis_image_L,gen_dis_image_S=MultiscaleDiscriminator(input_image,training=True)\n",
    "        L_target,S_target=MultiscaleDiscriminator(target,training=True)\n",
    "        \n",
    "        total_gen_loss,gan_loss,l1_loss=Generator_loss(target,gen_dis_image_L,gen_dis_image_S,gen_image)\n",
    "        \n",
    "        total_Dis_loss=MultiscaleDiscriminator_loss(L_target,S_target,gen_dis_image_L,gen_dis_image_S)\n",
    "    generator_gradient=gen_tape.gradient(total_gen_loss,Generator.trainable_variables)\n",
    "    \n",
    "    discriminator_gradient=disc_tape.gradient(total_Dis_loss,MultiscaleDiscriminator.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(generator_gradient,Generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(generator_gradient,MultiscaleDiscriminator.trainable_variables))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_ds, epochs, test_ds):\n",
    "    for epoch in range(epochs):\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        for example_input, example_target in test_ds.take(1):\n",
    "            generate_images(generator, example_input, example_target)\n",
    "        print(\"Epoch: \", epoch)\n",
    "\n",
    "        # Train\n",
    "        for n, (input_image, target) in train_ds.enumerate():\n",
    "            print('.', end='')\n",
    "            if (n+1) % 100 == 0:\n",
    "                print()\n",
    "            train_step(input_image, target, epoch)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
