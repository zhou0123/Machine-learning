{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import zipfile\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "import keras_contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Spade(num2,x,segmap,num):\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    \n",
    "    x=tf.keras.layers.BatchNormalization()(x)\n",
    "    segmap=tf.image.resize(segmap,[4*num,4*num])#调整图片大小\n",
    "    segmap=tf.keras.layers.Conv2D(128,3,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(segmap)\n",
    "    segmap=tf.keras.layers.ReLU()(segmap)\n",
    "    \n",
    "    gamma=tf.keras.layers.Conv2D(num2,3,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(segmap)\n",
    "    \n",
    "    beta=tf.keras.layers.Conv2D(num2,3,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(segmap)\n",
    "    \n",
    "    return (gamma+1)*x+beta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Spade_ResBlk(num2,x,segmap,filters,num):\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    \n",
    "    \n",
    "    x1=Spade(num2,x,segmap,num)\n",
    "    x1=tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1=tf.keras.layers.Conv2D(filters,3,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(x1)\n",
    "    \n",
    "    \n",
    "    x1=Spade(filters,x1,segmap,num)\n",
    "    x1=tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1=tf.keras.layers.Conv2D(filters,3,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(x1)\n",
    "    \n",
    "    x=Spade(num2,x,segmap,num)\n",
    "    x=tf.keras.layers.LeakyReLU()(x1)\n",
    "    x=tf.keras.layers.Conv2D(filters,3,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(x1)\n",
    "    \n",
    "    x=x+x1\n",
    "    \n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(filters):\n",
    "    initialiter=tf.random_normal_initializer(0,0.02)\n",
    "    \n",
    "    block=tf.keras.Sequential()\n",
    "    block.add(tf.keras.layers.Conv2D(filters,3,strides=2,padding='same',kernel_initializer=initialiter,use_bias=False))\n",
    "    block.add(keras_contrib.layers.InstanceNormalization())\n",
    "    block.add(tf.keras.layers.LeakyReLU())\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[ 1.09398223e-01, -7.01745391e-01, -3.91475797e-01, -6.80442691e-01,\n",
    "        1.01302110e-01, -2.06758165e+00, -6.15261076e-03,  1.38641715e+00,\n",
    "       -2.16011858e+00, -4.80607837e-01, -5.36878824e-01,  6.61370993e-01,\n",
    "        9.80835080e-01,  1.00194581e-01, -1.20660122e-02, -2.92659551e-01,\n",
    "        1.90165401e+00, -3.55604917e-01, -3.41223150e-01,  9.20889914e-01,\n",
    "       -4.10751253e-01, -3.04967910e-01,  4.59801555e-01, -9.15719122e-02,\n",
    "        8.23659301e-02,  6.73895359e-01, -7.51458883e-01,  6.69990301e-01,\n",
    "       -2.90337682e+00, -1.07552361e+00,  1.79552543e+00, -1.81808543e+00,\n",
    "        1.68375921e+00,  3.00740331e-01,  1.24897063e+00,  1.54214501e-02,\n",
    "       -2.21818113e+00, -6.40897080e-02, -8.21697235e-01, -1.34972692e-01,\n",
    "        2.34940362e+00, -7.03830421e-01,  5.06786704e-01, -6.99196637e-01,\n",
    "       -1.26937437e+00, -2.52861857e-01,  1.63582432e+00, -7.96311975e-01,\n",
    "       -3.15868974e-01, -5.67130595e-02, -9.54037011e-02, -1.56947002e-01,\n",
    "       -4.32539701e-01,  1.21812963e+00,  2.44811296e-01,  1.06517493e-03,\n",
    "        5.37360191e-01, -3.14026233e-03, -4.55410331e-01,  1.50040537e-01,\n",
    "       -1.65251696e+00,  8.37693751e-01, -8.84405971e-01, -8.05317521e-01,\n",
    "        1.51757407e+00, -1.44158435e+00, -2.14658093e+00,  7.56792873e-02,\n",
    "        1.08882594e+00,  7.18542516e-01,  9.70552444e-01, -1.62083730e-01,\n",
    "        2.36011427e-02, -3.14742517e+00, -1.59132302e+00, -3.47380936e-01,\n",
    "        1.08195893e-01, -1.51989698e-01, -2.19788939e-01,  1.27668834e+00,\n",
    "        1.03366423e+00, -1.93199742e+00, -6.66437522e-02, -4.05270517e-01,\n",
    "        8.54746938e-01,  1.92735076e+00, -6.11654878e-01,  2.68646866e-01,\n",
    "       -6.33371532e-01,  3.76523793e-01,  7.92135119e-01, -1.49863124e+00,\n",
    "       -4.46011536e-02,  4.74136055e-01,  1.02864766e+00,  8.89996469e-01,\n",
    "        6.75564468e-01, -1.30954355e-01,  4.94244576e-01,  7.45899558e-01,\n",
    "       -1.56613335e-01,  1.36730075e+00,  1.68628380e-01,  3.53314658e-03,\n",
    "        9.03990090e-01,  1.40195444e-01,  9.85414833e-02,  4.19275254e-01,\n",
    "       -3.36481519e-02,  2.45326549e-01,  3.54516953e-02, -1.18209696e+00,\n",
    "       -8.56581450e-01, -7.61776924e-01, -1.38177598e+00, -2.66133845e-01,\n",
    "        1.45023775e+00,  1.41912496e+00,  1.44648060e-01, -3.14437523e-02,\n",
    "        6.65680051e-01,  3.58196586e-01, -3.91108215e-01, -5.19516408e-01,\n",
    "        1.32320571e+00,  5.18085122e-01,  1.75068307e+00, -1.03100896e-01,\n",
    "        1.83369660e+00, -3.15227365e+00, -1.65771887e-01,  1.35008901e-01,\n",
    "        9.73028541e-01,  9.16363239e-01,  6.70804977e-02,  1.64290369e+00,\n",
    "        1.10678589e+00,  7.80407131e-01, -7.64281154e-02,  9.81125057e-01,\n",
    "        1.15349877e+00, -1.07952583e+00,  4.37276691e-01, -9.56526920e-02,\n",
    "       -8.10703993e-01,  6.46177649e-01, -2.62691259e-01, -3.44538599e-01,\n",
    "       -3.27624917e-01, -1.30278456e+00,  3.30004036e-01, -1.46936297e+00,\n",
    "        8.58642533e-02,  2.49484509e-01,  1.05241692e+00,  2.04514652e-01,\n",
    "        1.08832610e+00, -1.73757032e-01, -2.77286887e-01,  9.67025936e-01,\n",
    "       -2.05639100e+00, -8.07983875e-01,  1.58234465e+00,  5.64972997e-01,\n",
    "        5.91350913e-01, -1.40839130e-01, -5.42346776e-01,  1.33135033e+00,\n",
    "       -2.24199295e-01, -4.79004979e-01,  6.44344151e-01, -1.65611947e+00,\n",
    "       -4.11438584e-01, -1.14152487e-02, -1.81588328e+00, -6.95155025e-01,\n",
    "       -2.41588354e-01,  1.52799892e+00, -1.07857645e+00, -2.46833473e-01,\n",
    "       -7.85873115e-01,  1.19508058e-01, -7.70763695e-01,  2.64164233e+00,\n",
    "        2.96800613e-01, -2.86061436e-01,  1.89369798e+00,  5.50864816e-01,\n",
    "       -7.57534742e-01,  8.85300413e-02, -3.93872231e-01,  1.30517602e+00,\n",
    "       -2.31828284e+00, -1.59819078e+00,  5.88336825e-01, -1.12500146e-01,\n",
    "       -5.14462173e-01,  1.05639309e-01,  8.68221879e-01, -2.21772552e+00,\n",
    "        8.25944364e-01, -4.18995500e-01, -4.38051373e-01, -1.35572326e+00,\n",
    "        9.16148365e-01,  1.13186345e-01,  1.31754375e+00,  6.73261702e-01,\n",
    "       -1.49814993e-01, -8.13537121e-01, -5.16351819e-01, -3.73705357e-01,\n",
    "       -1.99787974e-01, -1.58680692e-01, -8.34456921e-01,  2.34511018e+00,\n",
    "        9.11160409e-02, -6.41909719e-01,  8.30103934e-01, -2.39636656e-02,\n",
    "       -1.19645226e+00,  8.12078118e-01,  5.57315767e-01, -2.54300666e+00,\n",
    "        1.73908964e-01,  8.98634851e-01, -1.32860139e-01, -1.89663732e+00,\n",
    "       -3.11678737e-01, -1.30957112e-01,  2.52645612e-01, -2.09982902e-01,\n",
    "        2.66717339e+00,  3.40309769e-01,  4.76272643e-01, -4.87283617e-01,\n",
    "       -3.59700948e-01, -1.54874396e+00,  6.54738843e-01,  6.31636143e-01,\n",
    "        6.61850393e-01,  1.30487251e+00, -2.40038246e-01, -1.01502395e+00,\n",
    "        2.06906533e+00,  2.23190635e-02, -8.87865841e-01, -2.24324360e-01,\n",
    "        5.66155493e-01, -1.11572206e+00,  4.65975523e-01, -1.04832935e+00,\n",
    "        1.58024025e+00,  1.57934809e+00,  6.82842553e-01,  9.98936415e-01]\n",
    "b=tf.convert_to_tensor(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GANGenerator():\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    inputs=tf.keras.layers.Input(shape=[256,256,3])#语义标签\n",
    "    inputs2=tf.keras.layers.Input(shape=[256,256,3])#target\n",
    "    encoder_blocks=[\n",
    "        encoder_block(64),\n",
    "        encoder_block(128),\n",
    "        encoder_block(256),\n",
    "        encoder_block(512),\n",
    "        encoder_block(512),\n",
    "        encoder_block(512)\n",
    "    ]\n",
    "    x1=inputs\n",
    "    x=inputs2\n",
    "    \n",
    "    for block in encoder_blocks:\n",
    "        x=block(x)\n",
    "    x=tf.keras.layers.Flatten()(x)\n",
    "    mean=tf.keras.layers.Dense(256)(x)\n",
    "    var=tf.keras.layers.Dense(256)(x)\n",
    "    \n",
    "    std=tf.exp(var*0.5)\n",
    "    x2=std*eps+mean\n",
    "    x2=tf.keras.layers.Flatten()(x2)\n",
    "    x2=tf.keras.layers.Dense(16384)(x2)\n",
    "    x2=tf.reshape(x2,[-1,4,4,1024])\n",
    "    num=1\n",
    "    x=Spade_ResBlk(1024,x2,x1,1024,num)\n",
    "    x=tf.keras.layers.UpSampling2D(size=(2,2))(x)\n",
    "    num=2\n",
    "    x=Spade_ResBlk(1024,x,x1,1024,num)\n",
    "    x=tf.keras.layers.UpSampling2D(size=(2,2))(x)\n",
    "    num=4\n",
    "    x=Spade_ResBlk(1024,x,x1,1024,num)\n",
    "    x=tf.keras.layers.UpSampling2D(size=(2,2))(x)\n",
    "    num=8\n",
    "    x=Spade_ResBlk(1024,x,x1,512,num)\n",
    "    x=tf.keras.layers.UpSampling2D(size=(2,2))(x)\n",
    "    num=16\n",
    "    x=Spade_ResBlk(512,x,x1,256,num)\n",
    "    x=tf.keras.layers.UpSampling2D(size=(2,2))(x)\n",
    "    num=32\n",
    "    x=Spade_ResBlk(256,x,x1,128,num)\n",
    "    x=tf.keras.layers.UpSampling2D(size=(2,2))(x)\n",
    "    num=64\n",
    "    x=Spade_ResBlk(128,x,x1,64,num)\n",
    "    \n",
    "    x=tf.keras.layers.Conv2D(3,3,strides=1,padding='same',kernel_initializer=initializer,use_bias=False)(x)\n",
    "    \n",
    "    output=tf.tanh(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=[inputs,inputs2],outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GANGenerator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_block(filters):\n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    \n",
    "    block=tf.keras.Sequential()\n",
    "    block.add(tf.keras.layers.Conv2D(filters,4,strides=2,padding='same',kernel_initializer=initializer,use_bias=False))\n",
    "    block.add(keras_contrib.layers.InstanceNormalization())\n",
    "    block.add(tf.keras.layers.LeakyReLU())\n",
    "    \n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    inputs=tf.keras.layers.Input(shape=[256,256,3])\n",
    "    inputs2=tf.keras.layers.Input(shape=[256,256,3])\n",
    "    x=tf.keras.layers.concatenate([inputs,inputs2])\n",
    "    \n",
    "    initializer=tf.random_normal_initializer(0,0.02)\n",
    "    \n",
    "    dis_blocks=[\n",
    "        dis_block(64),\n",
    "        dis_block(128),\n",
    "        dis_block(256),\n",
    "    ]\n",
    "    for block in dis_blocks:\n",
    "        x=block(x)\n",
    "    x=tf.keras.layers.Conv2D(512,2,strides=1,padding='valid',kernel_initializer=initializer,use_bias=False)(x)\n",
    "    x=keras_contrib.layers.InstanceNormalization()(x)\n",
    "    x=tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    x=tf.keras.layers.Conv2D(512,2,strides=1,padding='valid',kernel_initializer=initializer,use_bias=False)(x)\n",
    "    x1=tf.nn.sigmoid(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=[inputs,inputs2],outputs=x1)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Discriminator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=tf.keras.applications.VGG19(input_shape=(256,256,3),weights='imagenet',include_top=False)\n",
    "model.trainable=False\n",
    "slice1=tf.keras.Sequential()\n",
    "slice2=tf.keras.Sequential()\n",
    "slice3=tf.keras.Sequential()\n",
    "slice4=tf.keras.Sequential()\n",
    "slice5=tf.keras.Sequential()\n",
    "\n",
    "for i in range(4):\n",
    "    slice1.add(model.layers[i])\n",
    "for i in range(4,7):\n",
    "    slice2.add(model.layers[i])\n",
    "for i in range(7,12):\n",
    "    slice3.add(model.layers[i])\n",
    "for i in range(12,17):\n",
    "    slice4.add(model.layers[i])\n",
    "for i in range(17,22):\n",
    "    slice5.add(model.layers[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg19_input(image):\n",
    "    x1=slice1(image)\n",
    "    x2=slice2(x1)\n",
    "    x3=slice3(x2)\n",
    "    x4=slice4(x3)\n",
    "    x5=slice5(x4)\n",
    "    return [x1,x2,x3,x4,x5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 1/2\n",
    "def generator_loss(target,gen_dis_image,gen_image):#gen_image:(512,512,3) \n",
    "    gan_loss=tf.reduce_mean(1/2*tf.square(gen_dis_image-1))\n",
    "    \n",
    "    weight=[1/32,1/16,1/8,1/4,1]\n",
    "    x_1=vgg19_input(gen_image)\n",
    "    x_11=vgg19_input(target)\n",
    "    l1_loss=tf.reduce_mean(tf.abs(gen_image-target))\n",
    "    for i in range(len(x_1)):\n",
    "        l1_loss=l1_loss+weight[i]*tf.reduce_mean(tf.abs(x_1[i]-x_11[i]))\n",
    "    total_gen_loss=gan_loss+LAMBDA*l1_loss\n",
    "    \n",
    "    return total_gen_loss,l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = tf.reduce_mean(1/2*tf.square(disc_real_output-1))\n",
    "\n",
    "    generated_loss = tf.reduce_mean(1/2*tf.square(disc_generated_output))\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator=GANGenerator()\n",
    "discriminator=Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(input_image, target, epoch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator([input_image,target], training=True)\n",
    "\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "        gen_total_loss,gen_l1_loss = generator_loss(target,disc_generated_output,gen_output)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, target):\n",
    "    prediction = model([test_input,target], training=True)\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    display_list = [test_input[0], target[0], prediction[0]]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(image_file):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "\n",
    "    w = tf.shape(image)[1]\n",
    "\n",
    "    w = w // 2\n",
    "    real_image = image[:, w:, :]\n",
    "    input_image = image[:, :w, :]\n",
    "\n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    real_image = tf.cast(real_image, tf.float32)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(input_image, real_image, height, width):\n",
    "    input_image = tf.image.resize(input_image, [height, width],\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    real_image = tf.image.resize(real_image, [height, width],\n",
    "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    return input_image, real_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目标尺寸\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "def random_crop(input_image, real_image):\n",
    "    stacked_image = tf.stack([input_image, real_image], axis=0)\n",
    "    cropped_image = tf.image.random_crop(\n",
    "      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "    return cropped_image[0], cropped_image[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_jitter(input_image, real_image):\n",
    "    input_image, real_image = resize(input_image, real_image, 286, 286)\n",
    "\n",
    "    input_image, real_image = random_crop(input_image, real_image)\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        real_image = tf.image.flip_left_right(real_image)\n",
    "\n",
    "    return input_image, real_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image, real_image):\n",
    "    input_image = (input_image / 127.5) - 1\n",
    "    real_image = (real_image / 127.5) - 1\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_train(image_file):\n",
    "    input_image, real_image = load(image_file)\n",
    "    input_image, real_image = random_jitter(input_image, real_image)\n",
    "    input_image, real_image = normalize(input_image, real_image)\n",
    "\n",
    "    return input_image, real_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_test(image_file):\n",
    "    input_image, real_image = load(image_file)\n",
    "    input_image, real_image = resize(input_image, real_image,\n",
    "                                   IMG_HEIGHT, IMG_WIDTH)\n",
    "    input_image, real_image = normalize(input_image, real_image)\n",
    "\n",
    "    return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 400\n",
    "BATCH_SIZE = 2\n",
    "train_dataset = tf.data.Dataset.list_files('./data_coast/'+'*.jpg')\n",
    "train_dataset = train_dataset.map(load_image_train,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.list_files('./test_coast/'+'*.jpg')\n",
    "test_dataset = test_dataset.map(load_image_test)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_ds, epochs, test_ds):\n",
    "    num=len(train_ds.enumerate())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        for example_input, example_target in test_ds.take(1):\n",
    "            generate_images(generator, example_input, example_target)\n",
    "        print(\"\\r总进度完成%.2f %%\" % (epoch *100 /epochs), end=\"\")\n",
    "        print()\n",
    "        if epoch!=0 and epoch%5==0:\n",
    "                    generator.save('./Gau_coast%s.h5'%(epoch))\n",
    "                    discriminator.save('./Gau_Discriminator_coast%s.h5'%(epoch))\n",
    "                    print(epoch)\n",
    "        for n, (input_image, target) in train_ds.enumerate():\n",
    "            print(\"\\r子进度完成%.2f %%\" % (n *100 /num), end=\"\")\n",
    "            time1 = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            \n",
    "       \n",
    "            train_step(input_image, target, epoch)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_input, example_target in test_dataset.take(1):\n",
    "    generate_images(generator, example_input, example_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "fit(train_dataset, EPOCHS, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
