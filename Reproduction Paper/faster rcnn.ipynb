{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import VOCDetection\n",
    "import torch.optim as optim\n",
    "import PIL.Image as Image\n",
    "import PIL.ImageColor as ImageColor\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import PIL.ImageFont as ImageFont\n",
    "import imageio\n",
    "import math\n",
    "from torchvision.transforms import Resize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT = ImageFont.truetype('arial.ttf', 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16=vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16=vgg16.features[0:17].to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generate_anchors(nn.Module):\n",
    "    def __init__(self,base_size=16,rations=torch.tensor([0.5,1,2],device='cuda'),scales=2**torch.arange(3,6,device='cuda')):\n",
    "        super(generate_anchors,self).__init__()\n",
    "        \n",
    "        self.base=torch.tensor([0,0,15,15],device='cuda')\n",
    "        self.base_size=base_size\n",
    "        self.rations=rations\n",
    "        self.scales=scales\n",
    "        \n",
    "\n",
    "    def get_center(self,anchors):\n",
    "        \n",
    "        h=anchors[3]-anchors[1]+1\n",
    "        w=anchors[2]-anchors[0]+1\n",
    "        \n",
    "        x_ctr=(anchors[0]+anchors[2])/2\n",
    "        y_ctr=(anchors[1]+anchors[3])/2\n",
    "        \n",
    "        return h,w,x_ctr,y_ctr\n",
    "    \n",
    "    def change_on_rations(self,sizes):\n",
    "        \n",
    "        h,w,x_ctr,y_ctr=self.get_center(self.base)\n",
    "        \n",
    "        sizes=sizes.unsqueeze(1)\n",
    "        \n",
    "        ws=torch.sqrt(sizes/self.rations)\n",
    "        \n",
    "        \n",
    "        hs=sizes/ws\n",
    "        \n",
    "        ws=ws.reshape(-1,1)\n",
    "        hs=hs.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        anchors=torch.hstack((torch.round(torch.ones_like(ws)*x_ctr-(ws-1)*0.5),torch.round(torch.ones_like(hs)*y_ctr-(hs-1)*0.5),\n",
    "                            torch.round(torch.ones_like(ws)*x_ctr+(ws-1)*0.5),torch.round(torch.ones_like(hs)*y_ctr+(hs-1)*0.5)))\n",
    "        \n",
    "        return anchors\n",
    "    \n",
    "    def change_on_scales(self):\n",
    "        \n",
    "        h,w,x_ctr,y_ctr=self.get_center(self.base)\n",
    "        \n",
    "        sizes=h*w*self.scales*self.scales\n",
    "        \n",
    "        anchors=self.change_on_rations(sizes)\n",
    "        \n",
    "        return anchors\n",
    "    \n",
    "    def forward(self,height,width,feat_stride):\n",
    "        \n",
    "        anchors=self.change_on_scales()\n",
    "        \n",
    "        A=anchors.shape[0]\n",
    "        \n",
    "        shift_x=torch.arange(width,device='cuda')*feat_stride\n",
    "        shift_y=torch.arange(height,device='cuda')*feat_stride\n",
    "        \n",
    "        shift_x,shift_y=torch.meshgrid(shift_x,shift_y)\n",
    "        shift_x=shift_x.reshape(-1,1)\n",
    "        shift_y=shift_y.reshape(-1,1)\n",
    "        shifts=torch.hstack((shift_x,shift_y,shift_x,shift_y))\n",
    "        K=shifts.shape[0]\n",
    "        \n",
    "        shifts=shifts.reshape(1,K,4).permute((1,0,2))\n",
    "        anchors=anchors.reshape(1,A,4)\n",
    "        anchors=anchors+shifts\n",
    "        \n",
    "        anchors=anchors.reshape(A*K,4)\n",
    "        length=A*K\n",
    "        \n",
    "        return anchors,length\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class public_tools(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(public_tools,self).__init__()\n",
    "        \n",
    "    def change_on_pre(self,anchors,rpn_bbox_pred):\n",
    "        \n",
    "        ws=anchors[:,2]-anchors[:,0]+1\n",
    "        hs=anchors[:,3]-anchors[:,1]+1\n",
    "        ws=ws.unsqueeze(1)\n",
    "        hs=hs.unsqueeze(1)\n",
    "        x_ctr=(anchors[:,0]+anchors[:,2])/2\n",
    "        y_ctr=(anchors[:,1]+anchors[:,3])/2\n",
    "        x_ctr=x_ctr.unsqueeze(1)\n",
    "        y_ctr=y_ctr.unsqueeze(1)\n",
    "        \n",
    "        dx=rpn_bbox_pred[:,0].unsqueeze(1)\n",
    "        dy=rpn_bbox_pred[:,1].unsqueeze(1)\n",
    "        dw=rpn_bbox_pred[:,2].unsqueeze(1)\n",
    "        dh=rpn_bbox_pred[:,3].unsqueeze(1)\n",
    "        \n",
    "        pred_ctr_x=dx*ws+x_ctr\n",
    "        pred_ctr_y=dy*hs+y_ctr\n",
    "        pred_w=torch.exp(dw)*ws\n",
    "        pred_h=torch.exp(dh)*hs\n",
    "        pred_box=torch.zeros_like(rpn_bbox_pred,device='cuda')\n",
    "        \n",
    "        pred_box[:,0]=torch.squeeze(pred_ctr_x-0.5*pred_w)\n",
    "        pred_box[:,1]=torch.squeeze(pred_ctr_y-0.5*pred_h)\n",
    "        pred_box[:,2]=torch.squeeze(pred_ctr_x+0.5*pred_w)\n",
    "        pred_box[:,3]=torch.squeeze(pred_ctr_y+0.5*pred_h)\n",
    "        \n",
    "        return pred_box\n",
    "    def clip_boxes(self,proposals,im_shape):\n",
    "        proposals[:,0]=torch.maximum(torch.minimum(proposals[:,0],torch.tensor(im_shape[1]-1,device='cuda')),torch.tensor(0,device='cuda'))\n",
    "        proposals[:,1]=torch.maximum(torch.minimum(proposals[:,1],torch.tensor(im_shape[0]-1,device='cuda')),torch.tensor(0,device='cuda'))\n",
    "        proposals[:,2]=torch.maximum(torch.minimum(proposals[:,2],torch.tensor(im_shape[1]-1,device='cuda')),torch.tensor(0,device='cuda'))\n",
    "        proposals[:,3]=torch.maximum(torch.minimum(proposals[:,3],torch.tensor(im_shape[0]-1,device='cuda')),torch.tensor(0,device='cuda'))\n",
    "        \n",
    "        return proposals\n",
    "        \n",
    "    def nms(self,proposals,scores):\n",
    "        \n",
    "        Threshold=0.7\n",
    "        \n",
    "        x1=proposals[:,0]\n",
    "        y1=proposals[:,1]\n",
    "        x2=proposals[:,2]\n",
    "        y2=proposals[:,3]\n",
    "        \n",
    "        areas=(y2-y1+1)*(x2-x1+1)\n",
    "        scores=torch.squeeze(scores)\n",
    "        orders=(-1*scores).argsort()\n",
    "        keep=[]\n",
    "        while orders.size()[0]>0:\n",
    "            \n",
    "            i=orders[0]\n",
    "            \n",
    "            keep.append(i)\n",
    "            \n",
    "            xx1=torch.maximum(x1[i],x1[orders[1:]])\n",
    "            yy1=torch.maximum(y1[i],y1[orders[1:]])\n",
    "            xx2=torch.minimum(x2[i],x2[orders[1:]])\n",
    "            yy2=torch.minimum(y2[i],y2[orders[1:]])\n",
    "            \n",
    "            ws=torch.maximum(xx2-xx1+1,torch.tensor(0,device='cuda'))\n",
    "            hs=torch.maximum(yy2-yy1+1,torch.tensor(0,device='cuda'))\n",
    "            \n",
    "            inter=ws*hs\n",
    "            iou=inter/(areas[i]+areas[orders[1:]]-inter)\n",
    "            \n",
    "            index=torch.where(iou<Threshold)[0]\n",
    "            \n",
    "            orders=orders[index+1]\n",
    "            \n",
    "        keep=torch.tensor(keep,device='cuda')\n",
    "        \n",
    "        return keep\n",
    "    \n",
    "    def bbox_overlaps(self,anchors,gt_boxes):\n",
    "        \n",
    "        N,M=anchors.shape\n",
    "        K,M=gt_boxes.shape\n",
    "        \n",
    "        overlaps=torch.zeros(N,K,device='cuda')\n",
    "        \n",
    "        for k in range(K):\n",
    "            \n",
    "            area_gt=(gt_boxes[k,2]-gt_boxes[k,0]+1)+(gt_boxes[k,3]-gt_boxes[k,1]+1)\n",
    "            \n",
    "            xx1=torch.maximum(gt_boxes[k,0],anchors[:,0])\n",
    "            yy1=torch.maximum(gt_boxes[k,1],anchors[:,1])\n",
    "            xx2=torch.minimum(gt_boxes[k,2],anchors[:,2])\n",
    "            yy2=torch.minimum(gt_boxes[k,3],anchors[:,3])\n",
    "            hs=torch.maximum(torch.tensor(0,device='cuda'),yy2-yy1+1)\n",
    "            ws=torch.maximum(torch.tensor(0,device='cuda'),xx2-xx1+1)\n",
    "            areas=hs*ws\n",
    "            an_areas=(anchors[:,2]-anchors[:,0]+1)*(anchors[:,3]-anchors[:,1]+1)\n",
    "            \n",
    "            iou=areas/(area_gt+an_areas-areas)\n",
    "            \n",
    "            overlaps[:,k]=iou\n",
    "        \n",
    "        return overlaps\n",
    "    \n",
    "    def computer_targets(self,anchors,gt_box):\n",
    "        \n",
    "        an_ws=anchors[:,2]-anchors[:,0]+1\n",
    "        an_hs=anchors[:,3]-anchors[:,1]+1\n",
    "        ctr_x=(anchors[:,0]+anchors[:,2])/2\n",
    "        ctr_y=(anchors[:,1]+anchors[:,3])/2\n",
    "        \n",
    "        gt_ws=gt_box[:,2]-gt_box[:,0]+1\n",
    "        gt_hs=gt_box[:,3]-gt_box[:,1]+1\n",
    "        gt_ctr_x=(gt_box[:,0]+gt_box[:,2])/2\n",
    "        gt_ctr_y=(gt_box[:,1]+gt_box[:,3])/2\n",
    "        \n",
    "        targets_dx=(gt_ctr_x-ctr_x)/an_ws\n",
    "        targets_dy=(gt_ctr_y-ctr_y)/an_hs\n",
    "        targets_dw=torch.log(gt_ws/an_ws)\n",
    "        targets_dh=torch.log(gt_hs/an_hs)\n",
    "        \n",
    "        targets=torch.vstack((targets_dx,targets_dy,targets_dw,targets_dh)).T\n",
    "        \n",
    "        return targets\n",
    "    \n",
    "    def unmap(self,data,alls_num,inds,fill=0):\n",
    "        data=data.type(torch.float64)\n",
    "        if len(data.shape)==1:\n",
    "            \n",
    "            ret=torch.empty(alls_num,device='cuda',dtype=torch.float64)\n",
    "            ret.fill_(fill)\n",
    "            ret[inds]=data\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            ret=torch.empty(alls_num,data.shape[1],device='cuda',dtype=torch.float64)\n",
    "            ret.fill_(fill)\n",
    "        \n",
    "            ret[inds,:]=data\n",
    "        return ret\n",
    "        \n",
    "    def get_bbox_regression_labels(self,bbox_target_data, num_classes,clss):\n",
    "        \n",
    "        box_targets=torch.zeros(len(clss),4*num_classes,device='cuda')\n",
    "        box_inside_weights=torch.zeros(box_targets.shape,device='cuda')\n",
    "        \n",
    "        inds=torch.where(clss>0)[0]\n",
    "        \n",
    "        for ind in inds:\n",
    "            cls=clss[ind]\n",
    "            \n",
    "            strat=int(4*cls)\n",
    "            end=strat+4\n",
    "            box_targets[ind,strat:end]=bbox_target_data[ind]\n",
    "            box_inside_weights[ind,strat:end]=torch.tensor([1,1,1,1],device='cuda')\n",
    "            \n",
    "        return box_targets,box_inside_weights\n",
    "        \n",
    "        \n",
    "    def sample_rois(self,all_rois, all_scores, gt_boxes,gt_labels, fg_rois_per_image,rois_per_image, num_classes):\n",
    "        \n",
    "        overlaps=self.bbox_overlaps(all_rois,gt_boxes)\n",
    "        gt_argmax=overlaps.argmax(axis=1)\n",
    "        \n",
    "        max_overlaps=overlaps[torch.arange(len(overlaps)),gt_argmax]\n",
    "        labels=gt_labels[gt_argmax]\n",
    "        fg_inds=torch.where(max_overlaps>=0.5)[0]\n",
    "        \n",
    "        bg_inds=torch.where((max_overlaps>=0.1)&(max_overlaps<0.5))[0]\n",
    "        if fg_inds.size()[0]>0 and bg_inds.size()[0]>0:\n",
    "            \n",
    "            fg_rois_per_image=torch.min(torch.tensor(fg_rois_per_image,device='cuda'),\n",
    "                            torch.tensor(fg_inds.size()[0],device='cuda'))\n",
    "            fg_inds=np.array(fg_inds.to('cpu'))\n",
    "            fg_inds=np.random.choice(fg_inds,int(fg_rois_per_image),replace=False)\n",
    "            fg_inds=torch.from_numpy(fg_inds).to('cuda')\n",
    "            \n",
    "            bg_rois_per_image=rois_per_image-fg_rois_per_image\n",
    "            to_replace=bg_inds.size()[0]<bg_rois_per_image\n",
    "            bg_inds=np.array(bg_inds.to('cpu'))\n",
    "            bg_inds=np.random.choice(bg_inds,int(bg_rois_per_image),replace=to_replace)\n",
    "            bg_inds=torch.from_numpy(bg_inds).to('cuda')\n",
    "            \n",
    "            \n",
    "        if fg_inds.size()[0]>0:\n",
    "            \n",
    "            to_replace=fg_inds.size()[0]<rois_per_image\n",
    "            \n",
    "            fg_inds=np.array(fg_inds.to('cpu'))\n",
    "            fg_inds=np.random.choice(fg_inds,int(rois_per_image),replace=to_replace)\n",
    "            fg_inds=torch.from_numpy(fg_inds).to('cuda')\n",
    "            fg_rois_per_image=rois_per_image\n",
    "            \n",
    "        if bg_inds.size()[0]>0:\n",
    "            \n",
    "            to_replace=bg_inds.size()[0]<rois_per_image\n",
    "            \n",
    "            bg_inds=np.array(bg_inds.to('cpu'))\n",
    "            bg_inds=np.random.choice(bg_inds,int(rois_per_image),replace=to_replace)\n",
    "            bg_inds=torch.from_numpy(bg_inds).to('cuda')\n",
    "            fg_rois_per_image=0\n",
    "        fg_inds=fg_inds.to('cuda')\n",
    "        bg_inds=bg_inds.to('cuda')\n",
    "        keep_inds=torch.hstack((fg_inds,bg_inds))\n",
    "        \n",
    "        labels=labels[keep_inds]\n",
    "        labels[int(fg_rois_per_image):]=0\n",
    "        rois=all_rois[keep_inds]\n",
    "        rois_scores=all_scores[keep_inds]\n",
    "        \n",
    "        box_target_data=self.computer_targets(rois,gt_boxes[gt_argmax[keep_inds],:])\n",
    "        \n",
    "        box_targets,box_inside_weight=self.get_bbox_regression_labels(box_target_data,num_classes,labels)\n",
    "        \n",
    "        return labels,rois,rois_scores,box_targets,box_inside_weight\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=public_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class proposal_layers(nn.Module):\n",
    "    \n",
    "    def __init__(self,rpn_cls_prod,rpn_bbox_pred,anchors):\n",
    "        super(proposal_layers,self).__init__()\n",
    "        \n",
    "        self.rpn_cls_prod=rpn_cls_prod#(1,18,60,40)\n",
    "        self.rpn_bbox_pred=rpn_bbox_pred#(1,36,60,40)\n",
    "        self.anchors=anchors\n",
    "        \n",
    "    def forward(self,im_shape):\n",
    "        pre_nms_topN=12000\n",
    "        scores=self.rpn_cls_prod[:,9:,:,:]\n",
    "        scores=scores.reshape(-1,1)\n",
    "        self.rpn_bbox_pred=self.rpn_bbox_pred.reshape(-1,4)\n",
    "        proposals=tools.change_on_pre(self.anchors,self.rpn_bbox_pred)\n",
    "        proposals=tools.clip_boxes(proposals,im_shape)\n",
    "        scores=torch.squeeze(scores)\n",
    "        orders=(-1*scores).argsort()\n",
    "        \n",
    "        #选择前几位\n",
    "        orders=orders[:pre_nms_topN]\n",
    "        orders=torch.squeeze(orders)\n",
    "        proposals=proposals[orders,:]\n",
    "\n",
    "        scores=scores[orders]\n",
    "\n",
    "        keeps=tools.nms(proposals,scores)\n",
    "        keeps=keeps[:2000]\n",
    "        \n",
    "        proposals=proposals[keeps,:]\n",
    "        scores=scores[keeps]\n",
    "        \n",
    "        return proposals,scores\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class anchor_target_layer(nn.Module):\n",
    "    '''\n",
    "    第一层监督\n",
    "    '''\n",
    "    def __init__(self,rpn_cls_score, gt_boxes, im_shape, all_anchors,_feat_stride, num_anchors):\n",
    "        \n",
    "        super(anchor_target_layer,self).__init__()\n",
    "        self.rpn_cls_score=rpn_cls_score\n",
    "        self.gt_boxes=gt_boxes\n",
    "        self.im_shape=im_shape\n",
    "        \n",
    "        self._feat_stride=_feat_stride\n",
    "        self.all_anchors=all_anchors\n",
    "        self.num_anchors=num_anchors\n",
    "        \n",
    "    def forward(self):\n",
    "        \n",
    "        n,c,height,width=self.rpn_cls_score.shape\n",
    "        \n",
    "        M,K=self.gt_boxes.shape\n",
    "        all_num,l=self.all_anchors.shape\n",
    "        indexs=torch.where((self.all_anchors[:,0]>=0)&(self.all_anchors[:,1]>=0)&\n",
    "                           (self.all_anchors[:,2]<=self.im_shape[1])&(self.all_anchors[:,3]<=self.im_shape[0]))[0]\n",
    "        anchors=self.all_anchors[indexs]\n",
    "        labels=-1*torch.ones_like(indexs)\n",
    "        \n",
    "        overlaps=tools.bbox_overlaps(anchors,self.gt_boxes)#(N,K)\n",
    "        \n",
    "        argmax_overlaps=overlaps.argmax(axis=1)#(N,1)\n",
    "        max_overlaps=overlaps[torch.arange(len(indexs)),argmax_overlaps]\n",
    "\n",
    "        gt_argmax_overlaps=overlaps.argmax(axis=0)\n",
    "        gt_max_overlaps=overlaps[gt_argmax_overlaps,torch.arange(overlaps.shape[1])]\n",
    "        #gt_argmax_overlaps=torch.where(overlaps==gt_max_overlaps)[0]\n",
    "        labels[max_overlaps<0.3]=0\n",
    "        labels[gt_argmax_overlaps]=1\n",
    "        labels[max_overlaps>0.7]=1\n",
    "        \n",
    "        #防止positive过多\n",
    "        \n",
    "        num_fg=128\n",
    "        fg_inds=torch.where(labels==1)[0]\n",
    "        if len(fg_inds)>num_fg:\n",
    "            \n",
    "            fg_inds=np.array(fg_inds.to('cpu'))\n",
    "            dis_able=np.random.choice(fg_inds,len(fg_inds)-num_fg,replace=False)\n",
    "            dis_able=torch.from_numpy(dis_able).to('cuda')\n",
    "            \n",
    "            labels[dis_able]=-1\n",
    "            \n",
    "      \n",
    "        \n",
    "        num_bg=256-torch.sum(labels==1)\n",
    "        bg_inds=torch.where(labels==0)[0]\n",
    "        if len(bg_inds)>num_bg:\n",
    "            \n",
    "            bg_inds=np.array(bg_inds.to('cpu'))\n",
    "            num=len(bg_inds)-num_bg\n",
    "            num=np.array(num.to('cpu'))\n",
    "            dis_able=np.random.choice(bg_inds,num,replace=False)\n",
    "            dis_able=torch.from_numpy(dis_able).to('cuda')\n",
    "            labels[dis_able]=-1\n",
    "            \n",
    "        box_targets=tools.computer_targets(anchors,self.gt_boxes[argmax_overlaps,:])\n",
    "        \n",
    "        #权重\n",
    "        box_inside_weights=torch.zeros(len(indexs),4,device='cuda',dtype=torch.float64)\n",
    "        box_inside_weights[labels==1,:]=torch.tensor([1,1,1,1],device='cuda',dtype=torch.float64)\n",
    "        \n",
    "        box_outside_weights=torch.zeros(len(indexs),4,device='cuda',dtype=torch.float64)\n",
    "        num_example=torch.sum(labels>=0)\n",
    "        \n",
    "        pos_weight=torch.tensor([1,1,1,1],device='cuda',dtype=torch.float64)/num_example\n",
    "        neg_weight=torch.tensor([1,1,1,1],device='cuda',dtype=torch.float64)/num_example\n",
    "        \n",
    "        box_outside_weights[labels==1,:]=pos_weight\n",
    "        box_outside_weights[labels==0,:]=neg_weight\n",
    "        \n",
    "        labels=labels.type(torch.float64)\n",
    "        labels=tools.unmap(labels,all_num,indexs,fill=-1)\n",
    "        box_targets=tools.unmap(box_targets,all_num,indexs,fill=0)\n",
    "        box_inside_weights=tools.unmap(box_inside_weights,all_num,indexs,fill=0)\n",
    "        box_outside_weights=tools.unmap(box_outside_weights,all_num,indexs,fill=0)\n",
    "        \n",
    "        labels=labels.reshape(1,1,self.num_anchors*height,width)\n",
    "        rpn_labels=labels\n",
    "        \n",
    "        rpn_box_targets=box_targets.reshape(1,self.num_anchors*4,height,width)\n",
    "        rpn_box_inside_weights=box_inside_weights.reshape(1,self.num_anchors*4,height,width)\n",
    "        rpn_box_outside_weights=box_outside_weights.reshape(1,self.num_anchors*4,height,width)\n",
    "        \n",
    "        return rpn_labels,rpn_box_targets,rpn_box_inside_weights,rpn_box_outside_weights\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class proposal_target_layer(nn.Module):\n",
    "    \"\"\"\n",
    "    第二层监督\n",
    "    \"\"\"\n",
    "    def __init__(self,rpn_rois, rpn_scores, gt_boxes, _num_classes):\n",
    "        \n",
    "        super(proposal_target_layer,self).__init__()\n",
    "        \n",
    "        self.rpn_rois=rpn_rois\n",
    "        self.rpn_scores=rpn_scores\n",
    "        self.gt_boxes=gt_boxes\n",
    "        self.num_class=_num_classes\n",
    "    def forward(self):\n",
    "        \n",
    "        all_rois = self.rpn_rois\n",
    "        all_scores = self.rpn_scores\n",
    "        rois_per_image=128\n",
    "        fg_rois_per_image=32\n",
    "          #def sample_rois(self,all_rois, all_scores, gt_boxes,gt_labels, fg_rois_per_image,rois_per_image, num_classes):\n",
    "        \n",
    "        labels, rois, roi_scores, box_targets, box_inside_weights=tools.sample_rois(\n",
    "            all_rois,all_scores,self.gt_boxes[:,0:-1],self.gt_boxes[:,-1],fg_rois_per_image,rois_per_image,self.num_class)\n",
    "        \n",
    "        rois=rois.reshape(-1,4)\n",
    "\n",
    "        roi_scores=roi_scores.reshape(-1,1)\n",
    "        labels=labels.reshape(-1,1)\n",
    "        box_targets=box_targets.reshape(-1,4*self.num_class)\n",
    "        box_inside_weights=box_inside_weights.reshape(-1,4*self.num_class)\n",
    "        box_outside_weights=torch.tensor(box_inside_weights>0,device='cuda',dtype=torch.float64)\n",
    "        \n",
    "        return rois,roi_scores,labels,box_targets,box_inside_weights,box_outside_weights\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class faster_rcnn(nn.Module):\n",
    "    \n",
    "    def __init__(self,num_anchors,num_class):\n",
    "        super(faster_rcnn,self).__init__()\n",
    "        \n",
    "        self.num_anchors=num_anchors\n",
    "        self.num_class=num_class\n",
    "        \n",
    "        self.layer1=nn.Conv2d(256,512,kernel_size=3,padding=1,stride=1)\n",
    "        self.relu1=nn.ReLU()\n",
    "        \n",
    "        self.cls_score_layer=nn.Conv2d(512,num_anchors*2,kernel_size=1,padding=0,stride=1)\n",
    "        self.cls_score_relu=nn.ReLU()\n",
    "        \n",
    "        self.layer2=nn.Conv2d(512,num_anchors*4,kernel_size=1,padding=0,stride=1)\n",
    "        self.relu2=nn.ReLU()\n",
    "        \n",
    "        self.lin1=nn.Linear(50176,21)\n",
    "        self.lin2=nn.Linear(50176,21*4)\n",
    "    def reshape_layers(self,rpn_cls_score,dim):\n",
    "        \n",
    "        n,c,h,w=rpn_cls_score.shape\n",
    "        rpn_cls_score=rpn_cls_score.reshape(n,dim,-1,w)\n",
    "        \n",
    "        return rpn_cls_score\n",
    "        \n",
    "    def softmax(self,reshape_rpn_cls_score):\n",
    "        \n",
    "        rpn_cls_prob_reshape=nn.Softmax(dim=1)(reshape_rpn_cls_score)\n",
    "        \n",
    "        return rpn_cls_prob_reshape\n",
    "    def crop_pool_layer(self,net_conv,rois,feat_stride=8):\n",
    "        \n",
    "        '''\n",
    "        裁剪pooling\n",
    "        '''\n",
    "        n,c,height,width=net_conv.shape\n",
    "        height=(height)*feat_stride\n",
    "        width=(width)*feat_stride\n",
    "        \n",
    "        x1=(rois[:,0]/width).unsqueeze(1)\n",
    "        y1=(rois[:,1]/height).unsqueeze(1)\n",
    "        x2=(rois[:,2]/width).unsqueeze(1)\n",
    "        y2=(rois[:,3]/height).unsqueeze(1)\n",
    "        \n",
    "        num=len(x1)\n",
    "        \n",
    "        \n",
    "        bboxes=tf.constant(torch.hstack((y1,x1,y2,x2)).to('cpu').detach().numpy())\n",
    "        net_conv=net_conv.permute(0,2,3,1)\n",
    "        net_conv=tf.constant(net_conv.to('cpu').detach().numpy())\n",
    "        crops=tf.image.crop_and_resize(net_conv,bboxes,tf.zeros(num,dtype=tf.int32),[14,14])\n",
    "        \n",
    "        crops=tf.nn.max_pool2d(crops,[2,2],strides=1,padding='SAME')\n",
    "        if hasattr(torch.cuda, 'empty_cache'):\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        crops=torch.tensor(crops.numpy(),device='cuda')\n",
    "        crops=crops.permute(0,3,1,2)\n",
    "        print('a'*100)\n",
    "        return crops\n",
    "        \n",
    "        \n",
    "    def classification(self,pool5,num):\n",
    "        cls_score=self.lin1(pool5)\n",
    "        \n",
    "        cls_prod=self.softmax(cls_score)\n",
    "        cls_pred=torch.argmax(cls_prod,axis=1)\n",
    "        \n",
    "        box_pred=self.lin2(pool5)\n",
    "        \n",
    "        return cls_prod,box_pred\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,image,gt_box,is_training=True):\n",
    "        \n",
    "        list_c=[]\n",
    "        list_r=[]\n",
    "        n1,c1,h1,w1=image.shape\n",
    "        net_conv=vgg16(image)\n",
    "        \n",
    "        n,c,height,width=net_conv.shape\n",
    "        im_shape=[h1,w1]\n",
    "        all_anchors,length=generate_anchors()(height,width,feat_stride=8)\n",
    "        rpn=self.layer1(net_conv)\n",
    "        rpn=self.relu1(rpn)\n",
    "        \n",
    "        \n",
    "        #类别预测\n",
    "        rpn_cls_score=self.cls_score_layer(rpn)\n",
    "        rpn_cls_score=self.cls_score_relu(rpn_cls_score) #(1,18,60,40)#(512,14,14)\n",
    "        reshape_rpn_cls_score=self.reshape_layers(rpn_cls_score,dim=2)\n",
    "        \n",
    "        rpn_cls_prod_reshape=self.softmax(reshape_rpn_cls_score)\n",
    "        \n",
    "        rpn_cls_pred=torch.argmax(rpn_cls_prod_reshape.reshape(-1,2),axis=1)\n",
    "        \n",
    "        rpn_cls_prod=self.reshape_layers(rpn_cls_prod_reshape,dim=self.num_anchors*2)#(1,18,60,40)\n",
    "        \n",
    "        #边框targets预测\n",
    "\n",
    "        rpn_bbox_pred=self.layer2(rpn)\n",
    "        rpn_bbox_pred=self.relu2(rpn_bbox_pred)#(1,36,60,40)\n",
    "        rpn_labels,rpn_box_targets,rpn_box_inside_weights,rpn_box_outside_weights=anchor_target_layer(rpn_cls_score,gt_box,im_shape,\n",
    "                                         all_anchors, _feat_stride=8,num_anchors=9)()\n",
    "        list_r=[rpn_labels,rpn_box_targets,rpn_box_inside_weights,rpn_box_outside_weights]\n",
    "        if is_training:\n",
    "            rois,rios_scores=proposal_layers(rpn_cls_prod,rpn_bbox_pred,all_anchors)([h1,w1])\n",
    "            rois, roi_scores, labels, bbox_targets, bbox_inside_weights, bbox_outside_weights=proposal_target_layer(\n",
    "                rois,rios_scores,gt_box,self.num_class)()\n",
    "\n",
    "            list_c=[roi_scores, labels, bbox_targets, bbox_inside_weights, bbox_outside_weights]\n",
    "        \n",
    "        pool5=self.crop_pool_layer(net_conv,rois)\n",
    "        \n",
    "        p_n,p_c,p_h,p_w=pool5.shape\n",
    "        num=p_c*p_h*p_w\n",
    "        pool5=torch.reshape(pool5,(p_n,-1))\n",
    "        print(pool5.shape)\n",
    "        \n",
    "        cls_prod,box_pred=self.classification(pool5,num)\n",
    "        \n",
    "        return list_c,list_r,cls_prod,box_pred,rpn_cls_prod,rpn_bbox_pred,rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rcnn_loss(nn.Module):\n",
    "    def __init__(self,list_r,list_c,cls_prod,box_pred,rpn_cls_prod,rpn_bbox_pred):\n",
    "        \n",
    "        super(rcnn_loss,self).__init__()\n",
    "        #第二次监督\n",
    "        self.list_c=list_c\n",
    "        self.cls_prod=cls_prod\n",
    "        self.box_pred=box_pred\n",
    "        \n",
    "        #第一次监督\n",
    "        self.list_r=list_r\n",
    "        self.rpn_cls_prod=rpn_cls_prod\n",
    "        self.rpn_bbox_pred=rpn_bbox_pred\n",
    "    \n",
    "    def smooth_l1_loss(self, bbox_pred, bbox_targets, bbox_inside_weights, bbox_outside_weights, sigma=1.0,dim=[1]):\n",
    "        \n",
    "        box_diff=bbox_pred-bbox_targets\n",
    "        in_box_diff=box_diff*bbox_inside_weights\n",
    "        abs_in_box_diff=torch.abs(in_box_diff)\n",
    "        smoothL1_sign1=torch.less(abs_in_box_diff,1).detach()\n",
    "        \n",
    "        smoothL1_sign=torch.zeros_like(smoothL1_sign1,device='cuda',dtype=torch.float64)\n",
    "        smoothL1_sign[smoothL1_sign1]=1\n",
    "        in_loss_box1=torch.pow(in_box_diff,2)*(1/2)*smoothL1_sign+(abs_in_box_diff-0.5)*(1-smoothL1_sign)\n",
    "        \n",
    "        out_loss_box=bbox_outside_weights*in_loss_box1\n",
    "        loss_box=torch.mean(torch.sum(out_loss_box,axis=dim,dtype=torch.float64))\n",
    "        \n",
    "        return loss_box\n",
    "    \n",
    "    \n",
    "    def rpn_class_loss(self):\n",
    "        rpn_labels=self.list_r[0].reshape(-1,)\n",
    "        rpn_cls_score=self.rpn_cls_prod.reshape(-1,2)[:,0]\n",
    "        rpn_select=torch.where(torch.not_equal(rpn_labels,-1))[0]\n",
    "        rpn_cls_score=rpn_cls_score[rpn_select]\n",
    "        rpn_labels=rpn_labels[rpn_select]\n",
    "        rpn_class_loss1=torch.nn.BCEWithLogitsLoss()(rpn_cls_score,rpn_labels)\n",
    "        return rpn_class_loss1\n",
    "    \n",
    "\n",
    "    def rpn_box_loss(self):\n",
    "        rpn_box_targets,rpn_box_inside_weights,rpn_box_outside_weights=self.list_r[1],self.list_r[2],self.list_r[3]\n",
    "        rpn_box_loss1=self.smooth_l1_loss(self.rpn_bbox_pred,\n",
    "                                          rpn_box_targets,rpn_box_inside_weights,rpn_box_outside_weights,sigma=3,dim=[1, 2, 3])\n",
    "        return rpn_box_loss1\n",
    "    \n",
    "\n",
    "    def rcnn_class_loss(self):\n",
    "        \n",
    "        labels=self.list_c[1]\n",
    "        label=torch.zeros_like(self.cls_prod,device='cuda',dtype=torch.float64)\n",
    "        label[torch.arange(len(label)),torch.squeeze(labels)]=1\n",
    "        rcnn_class_loss1=torch.nn.BCEWithLogitsLoss()(self.cls_prod,label)\n",
    "        \n",
    "        return rcnn_class_loss1\n",
    "    \n",
    "    def rcnn_box_loss(self):\n",
    "        \n",
    "        box_targets,box_inside_weight,box_outside_weight=self.list_c[0],self.list_c[2],self.list_c[3]\n",
    "        rcnn_box_loss1=self.smooth_l1_loss(self.box_pred,box_targets,box_inside_weight,box_outside_weight)\n",
    "        \n",
    "        return rcnn_box_loss1\n",
    "    def forward(self):\n",
    "        \n",
    "        loss=self.rpn_class_loss()+self.rpn_box_loss()+self.rcnn_class_loss()+self.rcnn_box_loss()\n",
    "        \n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_one(images,xmin,ymin,xmax,ymax,display_str,font,color='red',thickness=4):\n",
    "        \n",
    "    draw = ImageDraw.Draw(images)\n",
    "    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom),\n",
    "             (right, top), (left, top)], width=thickness, fill=color)\n",
    "    text_bottom = bottom\n",
    "    text_width, text_height = font.getsize(display_str)\n",
    "    margin = np.ceil(0.05 * text_height)\n",
    "    draw.rectangle(\n",
    "      [(left, text_bottom - text_height - 2 * margin), (left + text_width,\n",
    "                                                        text_bottom)],\n",
    "      fill=color)\n",
    "    draw.text(\n",
    "      (left + margin, text_bottom - text_height - margin),\n",
    "      display_str,\n",
    "      fill='red',\n",
    "      font=font)\n",
    "\n",
    "    return images\n",
    "def draw_it(image,labels,box):\n",
    "    \n",
    "    num_box=box.size()[0]\n",
    "    image=torch.squeeze(image)\n",
    "    image=image.permute(1,2,0)\n",
    "    image=image.to('cpu').numpy()\n",
    "    image=np.round((image*0.5+0.5)*255)\n",
    "    image=image.astype(np.uint8)\n",
    "    image=Image.fromarray(image)\n",
    "    for i in range(num_box):\n",
    "        the_class=labels[i]\n",
    "        xmin,ymin,xmax,ymax=box[i,0],box[i,1],box[i,2],box[i,3]\n",
    "        image=draw_one(image,xmin,ymin,xmax,ymax,'%s'%(the_class),FONT)\n",
    "    image=torch.tensor(np.array(image))  \n",
    "    return image   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=faster_rcnn(num_anchors=9,num_class=21,).cuda()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001) #设置优化器和学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rcnn(epoches,images,datasets):\n",
    "    print(len(images))\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    length=len(dataset)\n",
    "    net.train()\n",
    "    for i in range(epoches):\n",
    "        \n",
    "        num=0\n",
    "        for j in range(len(images)):\n",
    "            print(num)\n",
    "            optimizer.zero_grad()\n",
    "            image=images[j]\n",
    "            image=image.unsqueeze(0)\n",
    "            gt_box=torch.tensor(dataset[j],device='cuda')\n",
    "          \n",
    "            \n",
    "            image = image.to(device)\n",
    "            gt_box = gt_box.to(device)\n",
    "            num+=1\n",
    "            list_c,list_r,cls_prod,box_pred,rpn_cls_prod,rpn_bbox_pred ,rois=net(image,gt_box)\n",
    "            \n",
    "            loss=rcnn_loss(list_r,list_c,cls_prod,box_pred,rpn_cls_prod,rpn_bbox_pred)()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            if num%1000==0:\n",
    "                index1=cls_prod.argmax(axis=1)\n",
    "                box_pred2=torch.zeros_like(box_pred[:,0:4])\n",
    "                for i in range(len(box_pred2)):\n",
    "                    box_pred2[i]=box_pred[i,index1[i]:index1[i]+4]\n",
    "                cls_prod=cls_prod[torch.arange(len(index1)),index1]\n",
    "                index2=torch.where(cls_prod>0.8)[0]\n",
    "                cls_prod=torch.round(cls_prod[index2]).type(torch.int)\n",
    "                if len(index2)==0:\n",
    "                    break\n",
    "                else:\n",
    "                    boxes=tools.change_on_pre(rois,box_pred2)[index2,:]\n",
    "                    boxes=torch.round(boxes).type(torch.int)\n",
    "                    list_name=[]\n",
    "                    for i in range(len(cls_prod)):\n",
    "                        list_name.append(name[cls_prod[i]])\n",
    "                    image=draw_it(image,list_name,boxes)\n",
    "                    image=torch.squeeze(image.to('cpu'))\n",
    "                    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tramforms=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=VOCDetection('C:/数据//目标检测voc2007',year='2007',image_set='train',download=False,transform=train_tramforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coo_image(train):\n",
    "    data_set=[]\n",
    "    images=[]\n",
    "    for i in range(len(train)):\n",
    "        data=[]\n",
    "        for j in range(len(train[i][1]['annotation']['object'])):\n",
    "        \n",
    "            xmin=int(train[i][1]['annotation']['object'][j]['bndbox']['xmin'])\n",
    "            ymin=int(train[i][1]['annotation']['object'][j]['bndbox']['ymin'])\n",
    "            xmax=int(train[i][1]['annotation']['object'][j]['bndbox']['xmax'])\n",
    "            ymax=int(train[i][1]['annotation']['object'][j]['bndbox']['ymax'])\n",
    "            name=train[i][1]['annotation']['object'][j]['name']\n",
    "            data.append([xmin,ymin,xmax,ymax,name])\n",
    "            \n",
    "        image=train[i][0]\n",
    "        data_set.append(data)\n",
    "        images.append(image)\n",
    "        \n",
    "        if i==23:\n",
    "            break\n",
    "        \n",
    "    return data_set,images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets1,images1=get_coo_image(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['nan','cow', 'aeroplane', 'bottle', 'bird', 'motorbike', 'person', 'tvmonitor', 'sofa', 'car', 'boat', 'cat', 'horse', 'train', 'bus', 'bicycle', 'chair', 'dog', 'pottedplant', 'sheep', 'diningtable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=datasets1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    for j in range(len(dataset[i])):\n",
    "        dataset[i][j][-1]=name.index(dataset[i][j][-1])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image1=[images1[25]]\n",
    "#dataset1=[dataset[25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rcnn(3,images1,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
